{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Label data demo\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install rasterio\n",
    "!pip install exactextract\n",
    "!pip install mapclassify"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import subprocess\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "import rasterio\n",
    "import rasterio.features\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "from rasterio.mask import mask\n",
    "from rasterio.merge import merge\n",
    "from rasterio.io import MemoryFile\n",
    "from exactextract import exact_extract\n",
    "from matplotlib.patches import Rectangle\n",
    "from shapely.geometry import box, Polygon, MultiPolygon, GeometryCollection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MOSAIKS grid\n",
    "\n",
    "The standard resolution of MOSAIKS is a global grid at 0.01° resolution. Each grid cell is approximately 1 km² at the equator. The grid is often represented as a point grid, where each point is the center of a grid cell. This means that standard MOSAIKS features come with a latitude and longitude coordinate, which is the center of the grid cell.\n",
    "\n",
    "Here we show several ways to create a MOSAIKS grid for a given location.\n",
    "\n",
    "> It is important to note that the grid is standardised such that the grid cells are centered at intervals of 0.005 degrees (e.g., 10.005, 10.015, 10.025,...).\n",
    "\n",
    "There is no firm reason why this resolution was chosen, but it is a good compromise between resolution and computational efficiency. If a user is computing customized features for their application, they can choose a different resolution. However, it is important to note that the resolution of the grid will affect the computation time and the amount of data that needs to be stored.\n",
    "\n",
    "### Advantages of the MOSAIKS grid\n",
    "\n",
    "The MOSAIKS grid has several advantages, but the promary advantage is that it helps avoid overlapping labels. Often data labels come with coordinates which are not standardly spaced. If you are forced to align your labels to a grid, you can avoid bleed over from one label to another. This is especially important when you are working with data that has a high degree of spatial autocorrelation.\n",
    "\n",
    "### Create a grid for a given location\n",
    "\n",
    "The following code creates a grid for a given location. The location can be given as a bounding box of the format `[minx, miny, maxx, maxy]`, a single polygon, or a dataframe with a geometry column. If a bounding box is given, the grid will be created for the bounding box. If a polygon is given, the grid will be created for the bounding box of the polygon, and then cropped to the polygon. If a dataframe is given, the grid will be created for the bounding box of each row, and then cropped to the geometry of that row, and it will be repeated for each row.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_grid(\n",
    "    borders,\n",
    "    resolution: float = 0.01,\n",
    "    geometry_col: str = \"geometry\",\n",
    "    id_col: str = \"NAME\",\n",
    "    return_ids: bool = False,\n",
    ") -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Create a grid of latitude and longitude coordinates for one or more geometries.\n",
    "    It can accept a bounding box, a single polygon (or other Shapely geometry),\n",
    "    or a GeoDataFrame with a geometry column.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    borders : list or tuple or shapely.geometry.BaseGeometry or geopandas.GeoDataFrame\n",
    "        - If list/tuple of length 4, interpreted as a bounding box: [minx, miny, maxx, maxy].\n",
    "        - If a Shapely geometry (Polygon, MultiPolygon, etc.), creates a single-row GeoDataFrame.\n",
    "        - If a GeoDataFrame, the function iterates over its rows.\n",
    "    resolution : float, optional\n",
    "        Grid resolution in degrees, default 0.01.\n",
    "    geometry_col : str, optional\n",
    "        Column name for the geometry in the resulting GeoDataFrame, by default \"geometry\".\n",
    "    id_col : str, optional\n",
    "        Column name in the GeoDataFrame to use as the ID column, or the name\n",
    "        for the new column if bounding box / single polygon is provided. Default is \"NAME\".\n",
    "    return_ids : bool, optional\n",
    "        If True, generate and return the unique IDs for each grid cell. This will create a\n",
    "        column 'unique_id' which follows the pattern 'lon_{lon}__lat_{lat}'. This option slows\n",
    "        down the overall operation. Default is False.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    pd.DataFrame\n",
    "        A DataFrame with columns:\n",
    "        - 'lat': latitude values (Y)\n",
    "        - 'lon': longitude values (X)\n",
    "        - `[id_col]`: the identifier for each geometry feature\n",
    "        - 'unique_id': a string combining [id_col] + lon/lat for uniqueness (optional)\n",
    "    \"\"\"\n",
    "\n",
    "    # 1. Convert input to a GeoDataFrame\n",
    "    gdf = _to_geodataframe(borders, geometry_col, id_col)\n",
    "\n",
    "    # 2. Ensure there's an ID column in the GeoDataFrame\n",
    "    if id_col not in gdf.columns:\n",
    "        # If user didn't provide an ID col for bounding box or single geometry,\n",
    "        # assign a placeholder ID. For a multi-row GDF, user is expected to pass\n",
    "        # an existing column name.\n",
    "        gdf[id_col] = [f\"feature_{i}\" for i in range(len(gdf))]\n",
    "\n",
    "    # 3. Rasterize each geometry and collect points\n",
    "    result_list = []\n",
    "    for _, row in gdf.iterrows():\n",
    "        geom = row[geometry_col]\n",
    "        this_id = row[id_col]\n",
    "\n",
    "        if geom.is_empty:\n",
    "            # Skip empty geometries\n",
    "            continue\n",
    "\n",
    "        minx, miny, maxx, maxy = geom.bounds\n",
    "\n",
    "        # ---- Create arrays for lat and lon values (Note: lat reversed) ----\n",
    "        # The 0.005 shift ensures that coordinates align on .005\n",
    "        lats = np.arange(\n",
    "            np.ceil(maxy / resolution) * resolution - 0.005, miny, -resolution\n",
    "        )\n",
    "        lons = np.arange(\n",
    "            np.ceil(minx / resolution) * resolution + 0.005, maxx, resolution\n",
    "        )\n",
    "\n",
    "        if len(lats) == 0 or len(lons) == 0:\n",
    "            # If bounding box is too small or resolution is large, might be empty\n",
    "            continue\n",
    "\n",
    "        # ---- Create a meshgrid ----\n",
    "        lon_grid, lat_grid = np.meshgrid(lons, lats)\n",
    "\n",
    "        # ---- Rasterize the geometry ----\n",
    "        out_shape = (len(lats), len(lons))\n",
    "        transform = rasterio.transform.from_bounds(\n",
    "            minx, miny, maxx, maxy, out_shape[1], out_shape[0]\n",
    "        )\n",
    "\n",
    "        mask = rasterio.features.rasterize(\n",
    "            [(geom, 1)],\n",
    "            out_shape=out_shape,\n",
    "            transform=transform,\n",
    "            fill=0,\n",
    "            dtype=np.uint8,\n",
    "        )\n",
    "\n",
    "        # ---- Extract the lat and lon values using the mask ----\n",
    "        lat_values = lat_grid[mask == 1]\n",
    "        lon_values = lon_grid[mask == 1]\n",
    "\n",
    "        # ---- Create a DataFrame and append to the result list ----\n",
    "        temp_df = pd.DataFrame({\"lat\": lat_values, \"lon\": lon_values})\n",
    "        temp_df[id_col] = this_id\n",
    "        result_list.append(temp_df)\n",
    "\n",
    "    # 4. Concatenate the results\n",
    "    if len(result_list) == 0:\n",
    "        final_result = pd.DataFrame(columns=[\"lat\", \"lon\", id_col, \"unique_id\"])\n",
    "    else:\n",
    "        final_result = pd.concat(result_list, ignore_index=True)\n",
    "        if return_ids:\n",
    "            # --- Create the unique_id column ---\n",
    "            # e.g. 'lon_-10.005__lat_9.995'\n",
    "            final_result[\"lon_rounded\"] = final_result[\"lon\"].round(3).astype(str)\n",
    "            final_result[\"lat_rounded\"] = final_result[\"lat\"].round(3).astype(str)\n",
    "\n",
    "            final_result[\"unique_id\"] = (\n",
    "                \"lon_\"\n",
    "                + final_result[\"lon_rounded\"]\n",
    "                + \"__lat_\"\n",
    "                + final_result[\"lat_rounded\"]\n",
    "            )\n",
    "\n",
    "            final_result.drop([\"lon_rounded\", \"lat_rounded\"], axis=1, inplace=True)\n",
    "\n",
    "    return final_result\n",
    "\n",
    "\n",
    "def _to_geodataframe(borders, geometry_col: str, id_col: str) -> gpd.GeoDataFrame:\n",
    "    \"\"\"\n",
    "    Internal helper that converts various input types into a standardized GeoDataFrame.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    borders : list/tuple, shapely geometry, or GeoDataFrame\n",
    "        Bounding box (list/tuple of length 4),\n",
    "        single Shapely geometry (Polygon, MultiPolygon, etc.),\n",
    "        or a GeoDataFrame.\n",
    "    geometry_col : str\n",
    "        The name of the geometry column to use or create.\n",
    "    id_col : str\n",
    "        The column in which to store or look for an ID (if relevant).\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    gpd.GeoDataFrame\n",
    "        A GeoDataFrame with columns [id_col, geometry_col].\n",
    "    \"\"\"\n",
    "    # Case 1: bounding box\n",
    "    if isinstance(borders, (list, tuple)) and len(borders) == 4:\n",
    "        minx, miny, maxx, maxy = borders\n",
    "        geom = box(minx, miny, maxx, maxy)\n",
    "        gdf = gpd.GeoDataFrame(\n",
    "            {id_col: [\"bbox_1\"], geometry_col: [geom]}, crs=\"EPSG:4326\"\n",
    "        )\n",
    "\n",
    "    # Case 2: single shapely geometry\n",
    "    elif isinstance(borders, (Polygon, MultiPolygon, GeometryCollection)):\n",
    "        gdf = gpd.GeoDataFrame(\n",
    "            {id_col: [\"geom_1\"], geometry_col: [borders]}, crs=\"EPSG:4326\"\n",
    "        )\n",
    "\n",
    "    # Case 3: GeoDataFrame\n",
    "    elif isinstance(borders, gpd.GeoDataFrame):\n",
    "        # If geometry_col does not exist, rename the current geometry column\n",
    "        # so everything is consistent\n",
    "        if geometry_col not in borders.columns:\n",
    "            borders = borders.rename(columns={borders.geometry.name: geometry_col})\n",
    "\n",
    "        gdf = borders.copy()\n",
    "        gdf = gdf.set_geometry(geometry_col)\n",
    "\n",
    "    else:\n",
    "        raise ValueError(\n",
    "            \"Unsupported input for 'borders'. Must be one of:\\n\"\n",
    "            \"1) [minx, miny, maxx, maxy]\\n\"\n",
    "            \"2) A Shapely geometry (Polygon, MultiPolygon, etc.)\\n\"\n",
    "            \"3) A GeoDataFrame\"\n",
    "        )\n",
    "\n",
    "    return gdf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create a grid for a bounding box\n",
    "\n",
    "In the following example, we create a grid for an arbitrary bounding box.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# format [minx, miny, maxx, maxy]\n",
    "bbox = [0.0, 0.0, 0.5, 0.5]\n",
    "bbox_grid_df = create_grid(\n",
    "    bbox,\n",
    "    resolution=0.01,\n",
    "    geometry_col=\"geometry\",\n",
    "    id_col=\"NAME\",\n",
    "    return_ids=True,\n",
    ")\n",
    "print(bbox_grid_df.head(), \"\\nShape: \", bbox_grid_df.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Visualize the grid\n",
    "\n",
    "Next we visualize the grid. To do this, we first create a GeoDataFrame with the grid points. We then buffer the points to create a polygon around each point. We use a `cap_style=3` to create square corners from the buffered points. Finally, we plot the grid points (green), the grid polygons (black), and the original bounding box (red).\n",
    "\n",
    "**Note:** the following code produces a warning from the buffer operation. This is because the buffer operation is being conducted on geometry in a geographic CRS. This warning can be safely ignored in the context of MOSAIKS.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bbox_grid_gdf = gpd.GeoDataFrame(\n",
    "    bbox_grid_df,\n",
    "    geometry=gpd.points_from_xy(bbox_grid_df.lon, bbox_grid_df.lat),\n",
    "    crs=\"EPSG:4326\",\n",
    ")\n",
    "bbox_grid_gdf.geometry = bbox_grid_gdf.geometry.buffer(0.005, cap_style=3)\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(6, 6))\n",
    "\n",
    "x_min, y_min, x_max, y_max = bbox\n",
    "rect = Rectangle(\n",
    "    (x_min, y_min),\n",
    "    x_max - x_min,\n",
    "    y_max - y_min,\n",
    "    fill=False,\n",
    "    color=\"red\",\n",
    "    linewidth=2,\n",
    ")\n",
    "ax.add_patch(rect)\n",
    "\n",
    "bbox_grid_gdf.plot.scatter(x=\"lon\", y=\"lat\", s=0.25, c=\"green\", ax=ax)\n",
    "bbox_grid_gdf.boundary.plot(ax=ax, color=\"black\", linewidth=0.5)\n",
    "\n",
    "ax.set_xlabel(\"Longitude\")\n",
    "ax.set_ylabel(\"Latitude\")\n",
    "plt.title(\"MOSAIKS grid cells with centroids\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create a grid for a polygon\n",
    "\n",
    "We can also create a grid for a polygon. In the following example, we create a grid for a polygon which defines the outline of a dinosaur. We see that our function creates a grid for the bounding box of the polygon, and then crops the grid to the polygon. This is useful to minimize the number of grid points that are created. This is especially true if the purpose of the grid is to define coordinates to upload to the MOSAIKS API for feature requests in the file query.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dino_polygon = Polygon(\n",
    "    [\n",
    "        (0.000, 0.444),\n",
    "        (0.136, 0.278),\n",
    "        (0.227, 0.333),\n",
    "        (0.318, 0.500),\n",
    "        (0.364, 0.500),\n",
    "        (0.409, 0.444),\n",
    "        (0.455, 0.444),\n",
    "        (0.500, 0.389),\n",
    "        (0.500, 0.333),\n",
    "        (0.364, 0.333),\n",
    "        (0.500, 0.278),\n",
    "        (0.455, 0.222),\n",
    "        (0.364, 0.278),\n",
    "        (0.364, 0.240),\n",
    "        (0.390, 0.200),\n",
    "        (0.390, 0.180),\n",
    "        (0.364, 0.180),\n",
    "        (0.318, 0.222),\n",
    "        (0.273, 0.056),\n",
    "        (0.318, 0.000),\n",
    "        (0.227, 0.000),\n",
    "        (0.182, 0.056),\n",
    "        (0.136, 0.000),\n",
    "        (0.091, 0.000),\n",
    "        (0.045, 0.056),\n",
    "        (0.091, 0.111),\n",
    "        (0.136, 0.167),\n",
    "        (0.045, 0.278),\n",
    "    ]\n",
    ")\n",
    "\n",
    "\n",
    "dino_grid_df = create_grid(\n",
    "    dino_polygon,\n",
    "    resolution=0.01,\n",
    "    return_ids=True,\n",
    ")\n",
    "\n",
    "print(dino_grid_df.head(), \"\\nShape: \", dino_grid_df.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Visualize the grid\n",
    "\n",
    "Here we visual our grid over the dinosaur polygon. Notice how the bounding box of the polygon is the same as the bounding box of the previous grid, though the grid is cropped to the polygon. Again, this is preferred to minimize the file sizes by not querying for unneccessary locations.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dino_grid_gdf = gpd.GeoDataFrame(\n",
    "    dino_grid_df,\n",
    "    geometry=gpd.points_from_xy(dino_grid_df.lon, dino_grid_df.lat),\n",
    "    crs=\"EPSG:4326\",\n",
    ")\n",
    "dino_grid_gdf.geometry = dino_grid_gdf.geometry.buffer(0.005, cap_style=3)\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(6, 6))\n",
    "\n",
    "x, y = dino_polygon.exterior.xy\n",
    "ax.plot(x, y, color=\"red\")\n",
    "\n",
    "dino_grid_gdf.plot.scatter(x=\"lon\", y=\"lat\", s=0.25, c=\"green\", ax=ax)\n",
    "\n",
    "dino_grid_gdf.boundary.plot(ax=ax, color=\"black\", linewidth=0.5)\n",
    "\n",
    "ax.set_xlabel(\"Longitude\")\n",
    "ax.set_ylabel(\"Latitude\")\n",
    "plt.title(\"MOSAIKS grid cells with centroids\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create a grid for a GeoDataFrame\n",
    "\n",
    "In the following example, we create a grid for a GeoDataFrame with a geometry column. The grid will be created for the bounding box of each row, and then cropped to the geometry of that row. First, we load an example of a GeoDataFrame with a geometry column, two countries in this case. We then create a grid for each country and visualize the grid for each country.\n",
    "\n",
    "This is slightly more practical use case, as it allows for the creation of a grid for multiple locations at once, while still minimizing the number of grid points that are created.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_url = \"https://github.com/wmgeolab/geoBoundaries/raw/9469f09/releaseData/gbOpen\"\n",
    "\n",
    "togo_shape_fp = f\"{base_url}/TGO/ADM0/geoBoundaries-TGO-ADM0.geojson\"\n",
    "benin_shape_fp = f\"{base_url}/BEN/ADM0/geoBoundaries-BEN-ADM0.geojson\"\n",
    "\n",
    "togo_gdf = gpd.read_file(togo_shape_fp)\n",
    "benin_gdf = gpd.read_file(benin_shape_fp)\n",
    "\n",
    "tgo_ben_gdf = pd.concat([togo_gdf, benin_gdf], ignore_index=True)\n",
    "tgo_ben_gdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tgo_ben_grid = create_grid(\n",
    "    tgo_ben_gdf,\n",
    "    resolution=0.01,\n",
    "    geometry_col=\"geometry\",\n",
    "    id_col=\"shapeISO\",\n",
    "    # return_ids=True,\n",
    ")\n",
    "tgo_ben_grid_gdf = gpd.GeoDataFrame(\n",
    "    tgo_ben_grid,\n",
    "    geometry=gpd.points_from_xy(tgo_ben_grid.lon, tgo_ben_grid.lat),\n",
    "    crs=\"EPSG:4326\",\n",
    ")\n",
    "tgo_ben_grid_gdf.geometry = tgo_ben_grid_gdf.geometry.buffer(0.005, cap_style=3)\n",
    "tgo_ben_grid_gdf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Visualize the grids\n",
    "\n",
    "Here we visualize our grids over the countries. Notice how the definition of the grid cells is lost as we zoom out. It is important to note that the maximum number of locations you can request via the MOSAIKS API is 100,000. In this case, it would be prudent to save a file for each country and upload them separately in 2 file queries.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(6, 6))\n",
    "\n",
    "tgo_ben_grid_gdf.plot(column=\"shapeISO\", ax=ax, legend=True)\n",
    "\n",
    "ax.set_xlabel(\"Longitude\")\n",
    "ax.set_ylabel(\"Latitude\")\n",
    "plt.title(\"MOSAIKS grid cells centroids\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sticking with the grid - preparing labels\n",
    "\n",
    "For the purposes of this demonstration, we will take advantage of the standardised grid and match our labels to this resolution. This is recomended for the most efficient use of the MOSAIKS API file query. Alternatively users may take advantage of precomputed aggregations of MOSAIKS features. These precomputed files come in 0.1 degree, 1 degree grids as well as features summarised to several levels of administrative division. We will cover label aggregation to these administrative divisions later in this demonstration.\n",
    "\n",
    "> There is no strict requirement to use this or any other grid system within the MOSAIKS framework. Using a different system may require the user to compute their own features.\n",
    "\n",
    "### Example 1: Point labels (lat/lon in a CSV)\n",
    "\n",
    "Scenario: You have a CSV containing locations (latitude, longitude) and some target variable (e.g., an economic indicator). In your notebook, you’ve loaded it into a DataFrame named XXXX.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = \"geofabrik\"\n",
    "\n",
    "if not os.path.exists(data_dir):\n",
    "    os.makedirs(data_dir, exist_ok=True)\n",
    "\n",
    "    !wget -O {data_dir}/togo-latest-free.zip https://download.geofabrik.de/africa/togo-latest-free.shp.zip\n",
    "\n",
    "    !unzip {data_dir}/togo-latest-free.zip -d {data_dir}\n",
    "\n",
    "    !rm {data_dir}/togo-latest-free.zip\n",
    "\n",
    "!ls -lhR {data_dir}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tgo_grid_gdf = tgo_ben_grid_gdf[tgo_ben_grid_gdf[\"shapeISO\"] == \"TGO\"]\n",
    "tgo_grid_gdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "togo_pois_gdf = gpd.read_file(os.path.join(data_dir, \"gis_osm_pois_free_1.shp\"))\n",
    "togo_pois_gdf = togo_pois_gdf[togo_pois_gdf[\"fclass\"].isin([\"school\"])]\n",
    "togo_pois_gdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# togo_pois_gdf.fclass.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# togo_pois_gdf.plot(column=\"fclass\", legend=False, figsize=(10, 10), markersize=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First, perform spatial join between the grid and POIs\n",
    "joined = gpd.sjoin(tgo_grid_gdf, togo_pois_gdf, how=\"left\", predicate=\"contains\")\n",
    "\n",
    "# Group by grid cell (using lat/lon) and fclass, then count\n",
    "summary = joined.groupby(\n",
    "    [\n",
    "        \"lat\",\n",
    "        \"lon\",\n",
    "    ],\n",
    "    as_index=False,\n",
    ").fclass.count()\n",
    "\n",
    "summary = gpd.GeoDataFrame(\n",
    "    summary,\n",
    "    geometry=gpd.points_from_xy(summary.lon, summary.lat),\n",
    "    crs=\"EPSG:4326\",\n",
    ")\n",
    "summary.geometry = summary.geometry.buffer(0.005, cap_style=3)\n",
    "summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# summary.explore()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example 2: Polygon Labels\n",
    "\n",
    "- Mines?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example 3: Line labels\n",
    "\n",
    "- Road length\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example 3: Raster Labels\n",
    "\n",
    "- Forest cover\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define target folder and ensure it exists\n",
    "gw_folder = \"global_forest_watch/70m_tree-cover\"\n",
    "os.makedirs(gw_folder, exist_ok=True)\n",
    "\n",
    "# Base URL for downloading the data\n",
    "base_url = \"https://data-api.globalforestwatch.org/dataset/wri_tropical_tree_cover/v2020/download/geotiff\"\n",
    "\n",
    "# This is the default API key for the Global Forest Watch API (Public Key)\n",
    "api_key = \"2d60cd88-8348-4c0f-a6d5-bd9adb585a8c\"\n",
    "\n",
    "# List of tile IDs to download\n",
    "tile_ids = [\"20N_010W\", \"20N_000E\", \"10N_000E\"]\n",
    "\n",
    "# Loop through each tile ID and download\n",
    "for tile_id in tile_ids:\n",
    "    output_path = os.path.join(gw_folder, f\"{tile_id}.tif\")\n",
    "    params = (\n",
    "        f\"?grid=10/40000&tile_id={tile_id}&pixel_meaning=percent&x-api-key={api_key}\"\n",
    "    )\n",
    "    url = f\"{base_url}{params}\"\n",
    "\n",
    "    print(f\"Downloading {tile_id}...\")\n",
    "    result = subprocess.run(\n",
    "        [\"wget\", \"-O\", output_path, url], capture_output=True, text=True\n",
    "    )\n",
    "\n",
    "    # Check for errors\n",
    "    if result.returncode == 0:\n",
    "        print(f\"Downloaded {tile_id} successfully to {output_path}\")\n",
    "    else:\n",
    "        print(f\"Error downloading {tile_id}: {result.stderr}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Load the Togo boundary GeoDataFrame and extract the geometry\n",
    "togo_gdf = gpd.read_file(togo_shape_fp)\n",
    "togo_boundary = [togo_gdf.geometry.values[0]]  # Ensure it's a list of geometries\n",
    "\n",
    "# Folder and output paths\n",
    "gw_files = [\"10N_000E.tif\", \"20N_000E.tif\", \"20N_010W.tif\"]\n",
    "out_raster = os.path.join(gw_folder, \"togo_gfw_tropical_tree_cover_2020.tif\")\n",
    "\n",
    "# Step 2: Read, crop, and store rasters in memory\n",
    "memory_files = []\n",
    "for raster_file in gw_files:\n",
    "    raster_path = os.path.join(gw_folder, raster_file)\n",
    "    with rasterio.open(raster_path) as src:\n",
    "        # Clip raster with the Togo boundary\n",
    "        out_image, out_transform = mask(src, togo_boundary, crop=True)\n",
    "        out_meta = src.meta.copy()\n",
    "\n",
    "        # Update metadata for cropped raster\n",
    "        out_meta.update(\n",
    "            {\n",
    "                \"driver\": \"GTiff\",\n",
    "                \"height\": out_image.shape[1],\n",
    "                \"width\": out_image.shape[2],\n",
    "                \"transform\": out_transform,\n",
    "            }\n",
    "        )\n",
    "\n",
    "        # Write to a MemoryFile\n",
    "        memfile = MemoryFile()\n",
    "        with memfile.open(**out_meta) as dataset:\n",
    "            dataset.write(out_image)\n",
    "        memory_files.append(memfile)\n",
    "\n",
    "# Step 3: Merge all cropped rasters into one\n",
    "datasets = [memfile.open() for memfile in memory_files]\n",
    "merged_data, merged_transform = merge(datasets)\n",
    "\n",
    "# Modify values outside 0 and 100 to NaN\n",
    "merged_data = merged_data.astype(\"float32\")  # Ensure the data type supports NaN\n",
    "merged_data[(merged_data < 0) | (merged_data > 100)] = np.nan\n",
    "\n",
    "# Step 4: Write the final merged raster to file\n",
    "# Step 4: Write the final merged raster to file with compression\n",
    "with rasterio.open(\n",
    "    out_raster,\n",
    "    \"w\",\n",
    "    driver=\"GTiff\",\n",
    "    height=merged_data.shape[1],\n",
    "    width=merged_data.shape[2],\n",
    "    count=merged_data.shape[0],\n",
    "    dtype=\"float32\",  # Ensure dtype matches merged_data\n",
    "    crs=src.crs,\n",
    "    transform=merged_transform,\n",
    "    tiled=True,  # Enable tiling\n",
    "    blockxsize=512,  # Set block size for optimal tiling\n",
    "    blockysize=512,\n",
    "    compress=\"lzw\",  # Apply LZW compression\n",
    "    nodata=np.nan,  # Set nodata value explicitly\n",
    ") as dst:\n",
    "    dst.write(merged_data)\n",
    "\n",
    "\n",
    "print(f\"Clipped, modified, and merged raster saved to: {out_raster}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the cropped file\n",
    "forest_cover_raster = f\"{gw_folder}/togo_gfw_tropical_tree_cover_2020.tif\"\n",
    "\n",
    "with rasterio.open(forest_cover_raster) as src:\n",
    "    togo_gfw = src.read(1)  # read the first band\n",
    "\n",
    "# Create the plot\n",
    "fig, ax = plt.subplots(figsize=(10, 10))\n",
    "im = ax.imshow(togo_gfw, cmap=\"YlGn\")  # YlGn is a good colormap for forest cover\n",
    "plt.colorbar(im, label=\"Tree Cover (%)\")\n",
    "ax.set_title(\"Togo Tree Cover 2020\")\n",
    "plt.show()\n",
    "\n",
    "# Print some basic statistics\n",
    "print(f\"Min value: {togo_gfw.min()}\")\n",
    "print(f\"Max value: {togo_gfw.max()}\")\n",
    "print(f\"Mean value: {togo_gfw.mean():.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the cropped file\n",
    "with rasterio.open(forest_cover_raster) as src:\n",
    "    # extract the raster values to the grid cells\n",
    "    extracted_vals = exact_extract(\n",
    "        src,\n",
    "        tgo_grid_gdf,\n",
    "        [\"mean\", \"median\", \"min\", \"max\"],\n",
    "        include_cols=[\"lat\", \"lon\"],\n",
    "        output=\"pandas\",\n",
    "    )\n",
    "\n",
    "# Make the extracted values into a GeoDataFrame\n",
    "extracted_vals = gpd.GeoDataFrame(\n",
    "    extracted_vals,\n",
    "    geometry=gpd.points_from_xy(extracted_vals.lon, extracted_vals.lat),\n",
    "    crs=\"EPSG:4326\",\n",
    ")\n",
    "\n",
    "# Buffer the points to create a small rectangular polygon around each point\n",
    "extracted_vals.geometry = extracted_vals.geometry.buffer(0.005, cap_style=3)\n",
    "\n",
    "extracted_vals.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "extracted_vals.plot(column=\"mean\", legend=True, figsize=(10, 10), cmap=\"YlGn\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# extracted_vals.explore(column=\"mean\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Aggregating labels to administrative divisions\n",
    "\n",
    "- Reduce the number of labels (pros and cons)\n",
    "- Reduce noise in the data\n",
    "- Increase the interpretability of the data\n",
    "- Not everything needs high resolution data\n",
    "- Can be predicted at higher resolution (super resolution)\n",
    "- Some data comes in aggregated already\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Label super resolution\n",
    "\n",
    "- Predicting at a higher resolution than the labels\n",
    "- Maybe not here? Might be better in the model notebook\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.linear_model import RidgeCV, Ridge\n",
    "# from sklearn.metrics import r2_score\n",
    "# from sklearn.model_selection import train_test_split\n",
    "\n",
    "# features = pd.read_parquet(\"features/features.parquet\")\n",
    "# features[[\"lat_temp\", \"lon_temp\"]] = features[\"unique_id\"].str.split(\"__\", expand=True)\n",
    "\n",
    "# features[\"lat\"] = features[\"lat_temp\"].str.replace(\"lat_\", \"\")\n",
    "# features[\"lon\"] = features[\"lon_temp\"].str.replace(\"lon_\", \"\")\n",
    "\n",
    "# features[\"lat\"] = features[\"lat\"].str.replace(\"--\", \".\").astype(float)\n",
    "# features[\"lon\"] = features[\"lon\"].str.replace(\"--\", \".\").astype(float)\n",
    "\n",
    "# features = features.drop([\"lat_temp\", \"lon_temp\"], axis=1)\n",
    "\n",
    "# features = gpd.GeoDataFrame(\n",
    "#     features,\n",
    "#     geometry=gpd.points_from_xy(features.lon, features.lat),\n",
    "#     crs=\"EPSG:4326\",\n",
    "# )\n",
    "\n",
    "# joined = extracted_vals.sjoin(features, predicate=\"contains\")\n",
    "\n",
    "# joined = joined.dropna(subset=[\"mean\"])\n",
    "\n",
    "# # joined[\"mean\"] = np.log1p(joined[\"mean\"])\n",
    "# joined[\"mean\"].plot.hist(bins=50)\n",
    "\n",
    "# feature_cols = [f\"planet_{i}\" for i in range(4000)]\n",
    "\n",
    "# X = joined[feature_cols]\n",
    "# y = joined[\"mean\"]\n",
    "\n",
    "# X_train, X_test, y_train, y_test = train_test_split(\n",
    "#     X, y, test_size=0.2, random_state=42\n",
    "# )\n",
    "\n",
    "# # alphas = np.logspace(-2, 2, base=10, num=5)\n",
    "# # ridge = RidgeCV(alphas=alphas, scoring=\"r2\", cv=5)\n",
    "\n",
    "# ridge = Ridge(alpha=0.1)\n",
    "\n",
    "\n",
    "# ridge.fit(X_train, y_train)\n",
    "\n",
    "# y_pred = np.maximum(ridge.predict(X_test), 0)\n",
    "\n",
    "# r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "# # print(f\"Best alpha: {ridge.alpha_}\")\n",
    "# # print(f\"Validation R2 performance {ridge.best_score_:0.2f}\")\n",
    "# print(f\"Test R2 performance {r2:.4f}\")\n",
    "\n",
    "# min_val = min(min(y_pred), min(y_test)) - 0.1\n",
    "# max_val = max(max(y_pred), max(y_test)) + 0.1\n",
    "\n",
    "# plt.figure(figsize=(6, 6))\n",
    "# plt.plot([min_val, max_val], [min_val, max_val], 'k--', lw=1)\n",
    "# plt.scatter(y_test, y_pred, alpha=0.5)\n",
    "\n",
    "# plt.xlabel('Observed Test Values')\n",
    "# plt.ylabel('Predicted Test Values')\n",
    "# plt.title('Observed vs Predicted Test Values')\n",
    "# plt.xlim(min_val, max_val)\n",
    "# plt.ylim(min_val, max_val)\n",
    "\n",
    "# # plt.text(\n",
    "# #     0.05, 0.95,\n",
    "# #     f'Validation R2: {ridge.best_score_:0.2f}',\n",
    "# #     transform=plt.gca().transAxes, fontsize=12,\n",
    "# #     verticalalignment='top'\n",
    "# # )\n",
    "# plt.text(\n",
    "#     0.05, 0.90,\n",
    "#     f'Test R2: {r2:.2f}',\n",
    "#     transform=plt.gca().transAxes, fontsize=12,\n",
    "#     verticalalignment='top'\n",
    "# )\n",
    "\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.linear_model import RidgeCV, Ridge\n",
    "# from sklearn.metrics import r2_score\n",
    "# from sklearn.model_selection import train_test_split\n",
    "\n",
    "# features = pd.read_parquet(\"features/features.parquet\")\n",
    "# features[[\"lat_temp\", \"lon_temp\"]] = features[\"unique_id\"].str.split(\"__\", expand=True)\n",
    "\n",
    "# features[\"lat\"] = features[\"lat_temp\"].str.replace(\"lat_\", \"\")\n",
    "# features[\"lon\"] = features[\"lon_temp\"].str.replace(\"lon_\", \"\")\n",
    "\n",
    "# features[\"lat\"] = features[\"lat\"].str.replace(\"--\", \".\").astype(float)\n",
    "# features[\"lon\"] = features[\"lon\"].str.replace(\"--\", \".\").astype(float)\n",
    "\n",
    "# features = features.drop([\"lat_temp\", \"lon_temp\"], axis=1)\n",
    "\n",
    "# features = gpd.GeoDataFrame(\n",
    "#     features,\n",
    "#     geometry=gpd.points_from_xy(features.lon, features.lat),\n",
    "#     crs=\"EPSG:4326\",\n",
    "# )\n",
    "\n",
    "# joined = summary.sjoin(features, predicate=\"contains\")\n",
    "\n",
    "# joined[\"fclass\"] = np.log1p(joined[\"fclass\"])\n",
    "# joined[\"fclass\"].plot.hist(bins=20)\n",
    "\n",
    "# feature_cols = [f\"planet_{i}\" for i in range(4000)]\n",
    "\n",
    "# X = joined[feature_cols]\n",
    "# y = joined[\"fclass\"]\n",
    "\n",
    "# X_train, X_test, y_train, y_test = train_test_split(\n",
    "#     X, y, test_size=0.2, random_state=42\n",
    "# )\n",
    "\n",
    "# # alphas = np.logspace(-2, 2, base=10, num=5)\n",
    "# # ridge = RidgeCV(alphas=alphas, scoring=\"r2\", cv=5)\n",
    "\n",
    "# ridge = Ridge(alpha=0.1)\n",
    "\n",
    "\n",
    "# ridge.fit(X_train, y_train)\n",
    "\n",
    "# y_pred = np.maximum(ridge.predict(X_test), 0)\n",
    "\n",
    "# r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "# # print(f\"Best alpha: {ridge.alpha_}\")\n",
    "# # print(f\"Validation R2 performance {ridge.best_score_:0.2f}\")\n",
    "# print(f\"Test R2 performance {r2:.4f}\")\n",
    "\n",
    "# min_val = min(min(y_pred), min(y_test)) - 0.1\n",
    "# max_val = max(max(y_pred), max(y_test)) + 0.1\n",
    "\n",
    "# plt.figure(figsize=(6, 6))\n",
    "# plt.plot([min_val, max_val], [min_val, max_val], 'k--', lw=1)\n",
    "# plt.scatter(y_test, y_pred, alpha=0.5)\n",
    "\n",
    "# plt.xlabel('Observed Test Values')\n",
    "# plt.ylabel('Predicted Test Values')\n",
    "# plt.title('Observed vs Predicted Test Values')\n",
    "# plt.xlim(min_val, max_val)\n",
    "# plt.ylim(min_val, max_val)\n",
    "\n",
    "# # plt.text(\n",
    "# #     0.05, 0.95,\n",
    "# #     f'Validation R2: {ridge.best_score_:0.2f}',\n",
    "# #     transform=plt.gca().transAxes, fontsize=12,\n",
    "# #     verticalalignment='top'\n",
    "# # )\n",
    "# plt.text(\n",
    "#     0.05, 0.90,\n",
    "#     f'Test R2: {r2:.2f}',\n",
    "#     transform=plt.gca().transAxes, fontsize=12,\n",
    "#     verticalalignment='top'\n",
    "# )\n",
    "\n",
    "# plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mosaiks",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
