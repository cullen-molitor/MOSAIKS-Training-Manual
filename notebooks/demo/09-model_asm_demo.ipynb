{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cp1-HnPiYUoh"
   },
   "source": [
    "# MOSAIKS Demonstration: Identifying Artisanal and Small-scale Mining in Sierra Leone\n",
    "\n",
    "This notebook demonstrates the use of machine learning and satellite imagery to identify potential artisanal and small-scale mining (ASM) sites in Sierra Leone.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UGgU2UYC8mvt"
   },
   "source": [
    "\n",
    "## Methodology\n",
    "\n",
    "The process involves the following steps:\n",
    "\n",
    "1. **Data Acquisition:**  Label data on known ASM sites is acquired. High-resolution satellite imagery is used to extract features for analysis.\n",
    "2. **Data Preprocessing:** The label and feature data are preprocessed and cleaned. This involves filtering for high-confidence labels, removing irrelevant mine types, and ensuring sufficient inspection coverage. The features are scaled and formatted for model training.\n",
    "3. **Data Joining:** The label and feature datasets are joined based on spatial intersection, creating a dataset linking site locations to satellite-derived features.\n",
    "4. **Model Training and Evaluation:** A machine learning model, specifically Ridge Regression with isotonic alibration, is trained on the joined dataset to predict the likelihood of ASM presence. The model is evaluated using metrics like the Receiver Operating Characteristic Area Under the Curve (ROC AUC).\n",
    "5. **Visualization and Interpretation:** The model results are visualized using maps and plots. Important features identified by the model are analyzed to understand the patterns associated with ASM sites.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0awZk_OLhDzX"
   },
   "source": [
    "## Setup\n",
    "\n",
    "This section outlines the necessary steps to set up the environment for running the analysis. It involves:\n",
    "\n",
    "1. **Loading Libraries:** Essential Python libraries for data manipulation, visualization, and machine learning are loaded.\n",
    "2. **Mounting Google Drive:** Your Google Drive is mounted to access project data stored on the cloud.\n",
    "3. **Defining Drive Directory:** The specific path to the project folder on your Google Drive is set.\n",
    "4. **Creating Local Directory:** A temporary local directory within Colab is created to accelerate data processing. Data is copied to this directory to improve performance.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "azwGr9_x8bfh"
   },
   "source": [
    "### Libraries\n",
    "\n",
    "This notebook utilizes several key Python libraries:\n",
    "\n",
    "* **Data Handling and Analysis:**  `pandas` and `numpy` provide fundamental data structures and functions for manipulating and analyzing data. `geopandas` extends these capabilities to work with geospatial data.\n",
    "* **Visualization:** `matplotlib.pyplot` and `seaborn` enable the creation of static and interactive visualizations, aiding in data exploration and result presentation.\n",
    "* **Machine Learning:** `sklearn` offers a comprehensive suite of tools for building and evaluating machine learning models, including algorithms like Ridge Regression and methods for data preprocessing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 6281,
     "status": "ok",
     "timestamp": 1731577686844,
     "user": {
      "displayName": "Cullen D Molitor",
      "userId": "02217726571370409329"
     },
     "user_tz": 0
    },
    "id": "eJWlXEaJNKWf",
    "outputId": "853cab24-68cf-4b37-fd65-00e623a96d5b"
   },
   "outputs": [],
   "source": [
    "!pip install mapclassify"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "executionInfo": {
     "elapsed": 5,
     "status": "ok",
     "timestamp": 1731577686844,
     "user": {
      "displayName": "Cullen D Molitor",
      "userId": "02217726571370409329"
     },
     "user_tz": 0
    },
    "id": "x6eczjTE2k3B"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import geopandas as gpd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from google.colab import drive\n",
    "from sklearn.linear_model import RidgeClassifier\n",
    "from sklearn.calibration import IsotonicRegression\n",
    "from sklearn.metrics import roc_auc_score, roc_curve\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "executionInfo": {
     "elapsed": 4,
     "status": "ok",
     "timestamp": 1731577686844,
     "user": {
      "displayName": "Cullen D Molitor",
      "userId": "02217726571370409329"
     },
     "user_tz": 0
    },
    "id": "MeUTFgbBx8SS"
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "from scipy.linalg import LinAlgWarning\n",
    "\n",
    "warnings.filterwarnings(\"ignore\", category=UserWarning, module=\"sklearn.linear_model._ridge\")\n",
    "warnings.filterwarnings(\"ignore\", category=LinAlgWarning, module=\"sklearn.linear_model._ridge\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "l4EFvpXXYwr3"
   },
   "source": [
    "### Mounting Google Drive\n",
    "\n",
    "Mounting Google Drive in Colab essentially connects your Google Drive storage to the Colab environment. This allows you to access files and folders stored in your Drive directly within your Colab notebook. Think of it as creating a shortcut to your Drive within Colab.\n",
    "\n",
    "**Why is this necessary?**\n",
    "\n",
    "Colab notebooks run on temporary virtual machines. Mounting your Drive ensures that you can load and save data to your personal storage, persisting even after the Colab session ends. It also enables seamless access to larger datasets stored in your Drive, which would be impractical to upload directly to Colab.\n",
    "\n",
    "After mounting Google Drive, we then define the path to the project folder on Google Drive. This directory contains the data files needed for the analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 6821,
     "status": "ok",
     "timestamp": 1731577693661,
     "user": {
      "displayName": "Cullen D Molitor",
      "userId": "02217726571370409329"
     },
     "user_tz": 0
    },
    "id": "2SoIEpYy23O9",
    "outputId": "a357ba16-6480-4c34-9bb6-47b22e1d2da3"
   },
   "outputs": [],
   "source": [
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "executionInfo": {
     "elapsed": 5,
     "status": "ok",
     "timestamp": 1731577693661,
     "user": {
      "displayName": "Cullen D Molitor",
      "userId": "02217726571370409329"
     },
     "user_tz": 0
    },
    "id": "kBTTV9zKIf5j",
    "outputId": "f521bb08-1e04-46d8-923e-39c1fa783830"
   },
   "outputs": [],
   "source": [
    "drive_directory = os.path.join(\n",
    "    \"/\",\n",
    "    \"content\",\n",
    "    \"drive\",\n",
    "    \"MyDrive\",\n",
    "    \"November 2024 Conference\",\n",
    ")\n",
    "drive_directory"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BA79h642hQNa"
   },
   "source": [
    "## Create a local directory\n",
    "\n",
    "This section creates a local directory within the Colab environment to store the project data. Data files are copied from the Google Drive directory to this local folder.\n",
    "\n",
    "**Why use a local directory?**  \n",
    "\n",
    "Accessing data locally on the Colab virtual machine (VM) significantly improves processing speed compared to reading directly from Google Drive. While copying the data initially takes a bit of time, this is outweighed by the performance gains during analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "executionInfo": {
     "elapsed": 18133,
     "status": "ok",
     "timestamp": 1731577711790,
     "user": {
      "displayName": "Cullen D Molitor",
      "userId": "02217726571370409329"
     },
     "user_tz": 0
    },
    "id": "5ITEdHZP3pdC",
    "outputId": "e44d4141-16f9-4cb8-9508-51bf3c32b63e"
   },
   "outputs": [],
   "source": [
    "local_dir = \"/content/data/\"\n",
    "\n",
    "os.makedirs(local_dir, exist_ok=True)\n",
    "\n",
    "files_to_copy = os.path.join(drive_directory, \"data\")\n",
    "\n",
    "shutil.copytree(files_to_copy, local_dir, dirs_exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FQoH3_d_6rlp"
   },
   "source": [
    "Here we take a look at the contents of the local drive to ensure we have the necessary files copied."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 18,
     "status": "ok",
     "timestamp": 1731577711790,
     "user": {
      "displayName": "Cullen D Molitor",
      "userId": "02217726571370409329"
     },
     "user_tz": 0
    },
    "id": "qXghaHUiqqyr",
    "outputId": "cebf8a54-88dd-45f7-cd72-943b6f0f422e"
   },
   "outputs": [],
   "source": [
    "!ls -lh /content/data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tXxa_X-AH21T"
   },
   "source": [
    "## Load in the ASM label data\n",
    "\n",
    "This section focuses on loading and preparing the artisanal and small-scale mining (ASM) label data for analysis. The data is read from a CSV file (`SLE_mines.csv`) located in the project directory.  Several preprocessing steps are then applied to ensure data quality and relevance:\n",
    "\n",
    "1. **Initial Loading and Column Selection:** The label data is loaded into a pandas DataFrame. Specific columns relevant to the analysis, such as location coordinates, mine type, confidence level, and inspection coverage, are selected.\n",
    "2. **Data Filtering:**\n",
    "   * Sites with low inspection coverage (less than 20%) are excluded, unless they are labeled as positive for ASM activity. This ensures that only sites with sufficient inspection data are considered.\n",
    "   * Sites classified as \"commercial\" mines are removed, as the focus is on artisanal and small-scale operations.\n",
    "   * Sites with low confidence levels (below 3) are filtered out to retain high-quality labels.\n",
    "3. **Data Restructuring:** The DataFrame is reset to ensure a contiguous index after filtering.\n",
    "4. **GeoDataFrame Creation:**  The DataFrame is converted into a GeoDataFrame using `geopandas`. This allows for spatial operations and visualizations by associating each site with a geographical point based on its longitude and latitude. This GeoDataFrame is used in subsequent steps for spatial analysis and joining with satellite features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 424
    },
    "executionInfo": {
     "elapsed": 17,
     "status": "ok",
     "timestamp": 1731577711791,
     "user": {
      "displayName": "Cullen D Molitor",
      "userId": "02217726571370409329"
     },
     "user_tz": 0
    },
    "id": "_Neh9B3euAwL",
    "outputId": "8ab62440-d412-45f4-adb9-74f3061c4b4d"
   },
   "outputs": [],
   "source": [
    "labels = pd.read_csv(os.path.join(local_dir, \"SLE_mines.csv\"))\n",
    "labels = labels[\n",
    "    [\n",
    "        \"lon\",\n",
    "        \"lat\",\n",
    "        \"unique_id\",\n",
    "        \"country\",\n",
    "        \"sample_type\",\n",
    "        \"mine_type\",\n",
    "        \"confidence\",\n",
    "        \"label\",\n",
    "        \"proportion_inspected\"\n",
    "    ]\n",
    "]\n",
    "labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 16,
     "status": "ok",
     "timestamp": 1731577711791,
     "user": {
      "displayName": "Cullen D Molitor",
      "userId": "02217726571370409329"
     },
     "user_tz": 0
    },
    "id": "JAMGws1-G3bK",
    "outputId": "b50ffa3a-f2c8-4ad8-a3d6-78cdd652037a"
   },
   "outputs": [],
   "source": [
    "labels = labels.loc[(labels[\"proportion_inspected\"] >= 0.2) | (labels[\"label\"] == 1)]\n",
    "labels.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 14,
     "status": "ok",
     "timestamp": 1731577711791,
     "user": {
      "displayName": "Cullen D Molitor",
      "userId": "02217726571370409329"
     },
     "user_tz": 0
    },
    "id": "eyy3G4lHGQRl",
    "outputId": "1cb9f0bf-1952-41e6-db53-e460b905e8dd"
   },
   "outputs": [],
   "source": [
    "labels = labels.loc[labels[\"mine_type\"] != \"commercial\"]\n",
    "labels.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 13,
     "status": "ok",
     "timestamp": 1731577711791,
     "user": {
      "displayName": "Cullen D Molitor",
      "userId": "02217726571370409329"
     },
     "user_tz": 0
    },
    "id": "pcJivt1mGXj7",
    "outputId": "46e70f41-c36e-466c-a2ea-2e955b87aea2"
   },
   "outputs": [],
   "source": [
    "labels = labels.loc[labels[\"confidence\"] >= 3]\n",
    "labels.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 424
    },
    "executionInfo": {
     "elapsed": 12,
     "status": "ok",
     "timestamp": 1731577711791,
     "user": {
      "displayName": "Cullen D Molitor",
      "userId": "02217726571370409329"
     },
     "user_tz": 0
    },
    "id": "2Y_4S3boHQd1",
    "outputId": "e5349b6c-5ea2-4126-e901-5a8fa6737d70"
   },
   "outputs": [],
   "source": [
    "labels = labels.reset_index(drop=True)\n",
    "labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 430
    },
    "executionInfo": {
     "elapsed": 11,
     "status": "ok",
     "timestamp": 1731577711791,
     "user": {
      "displayName": "Cullen D Molitor",
      "userId": "02217726571370409329"
     },
     "user_tz": 0
    },
    "id": "TbS3pwmg26nh",
    "outputId": "4dce882f-c034-4026-c6cf-b09386bdb319"
   },
   "outputs": [],
   "source": [
    "labels.groupby('label').size().plot(kind='barh', color=sns.palettes.mpl_palette('Dark2'))\n",
    "plt.gca().spines[['top', 'right',]].set_visible(False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FC3eS-KfB6V5"
   },
   "source": [
    "### Transforming Labels into a GeoDataFrame\n",
    "\n",
    "In this step, we convert the pandas DataFrame containing the ASM label data into a GeoDataFrame using the `geopandas` library. This transformation is crucial for enabling spatial analysis and visualization.\n",
    "\n",
    "**How it's done:**\n",
    "\n",
    "1. **Create GeoDataFrame:** We use the `geopandas.GeoDataFrame()` function to create a GeoDataFrame from the existing pandas DataFrame (`labels`).\n",
    "1. **Define Geometry:** Within the `GeoDataFrame()` function, we specify the `geometry` argument. This argument defines the spatial representation of each data point. We utilize `geopandas.points_from_xy()` to create point geometries from the longitude (`lon`) and latitude (`lat`) columns of the DataFrame.\n",
    "1. **Set Coordinate Reference System (CRS):** We also set the `crs` argument to \"EPSG:4326\". This defines the coordinate reference system used for the data, ensuring that the spatial information is interpreted correctly. EPSG:4326 is a common standard for geographic coordinates.\n",
    "\n",
    "**Why it's necessary:**\n",
    "\n",
    "* **Spatial Operations:** GeoDataFrames allow us to perform spatial operations, such as determining which labels intersect with satellite imagery features. This is essential for linking the ASM site locations to the extracted features.\n",
    "* **Visualization:** GeoDataFrames can be easily plotted on maps, enabling visualization of the spatial distribution of ASM sites. This aids in understanding the geographic patterns of ASM activity.\n",
    "* **Integration with Geospatial Tools:** GeoDataFrames are compatible with other geospatial tools and libraries, providing flexibility for further analysis and integration with GIS workflows.\n",
    "\n",
    "By transforming the labels into a GeoDataFrame, we empower our analysis with spatial capabilities, paving the way for more insightful explorations of ASM activity in Sierra Leone."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 424
    },
    "executionInfo": {
     "elapsed": 10,
     "status": "ok",
     "timestamp": 1731577711791,
     "user": {
      "displayName": "Cullen D Molitor",
      "userId": "02217726571370409329"
     },
     "user_tz": 0
    },
    "id": "GQqhPj23F1L5",
    "outputId": "2bd6bfce-48cf-4b19-f74e-a16f0ceceebc"
   },
   "outputs": [],
   "source": [
    "labels_gdf = gpd.GeoDataFrame(\n",
    "    labels,\n",
    "    geometry=gpd.points_from_xy(labels.lon, labels.lat),\n",
    "    crs=\"EPSG:4326\"\n",
    ")\n",
    "labels_gdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 720,
     "output_embedded_package_id": "1rdiZg-TX4SgHA5sEjANPZ_lJ7P15Tgwl"
    },
    "executionInfo": {
     "elapsed": 5523,
     "status": "ok",
     "timestamp": 1731577717305,
     "user": {
      "displayName": "Cullen D Molitor",
      "userId": "02217726571370409329"
     },
     "user_tz": 0
    },
    "id": "PBizK7_fM4DN",
    "outputId": "74b009ab-6b2d-4142-d101-41e89ea84ec7"
   },
   "outputs": [],
   "source": [
    "labels_gdf.explore(\n",
    "    column = \"mine_type\",\n",
    "    cmap = \"Dark2\",\n",
    "    tiles = \"CartoDB positron\",\n",
    "    categorical=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2IyvZ_wTbTFz"
   },
   "source": [
    "## Loading and Processing Satellite Features\n",
    "\n",
    "This section focuses on loading and preparing the satellite imagery features for analysis. These features, derived from high-resolution satellite imagery, are crucial for identifying potential ASM sites.\n",
    "\n",
    "**Loading the Features:**\n",
    "\n",
    "* The features are read from a Feather file (`SLE_features.feather`) stored in the project directory. Feather is a fast and efficient format for storing dataframes, making it ideal for handling large datasets like this.\n",
    "* The features are loaded into a pandas DataFrame. Each row represents a specific location, identified by an `image_id`, and the columns contain the extracted random convolutional features.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 429
    },
    "executionInfo": {
     "elapsed": 4778,
     "status": "ok",
     "timestamp": 1731577722081,
     "user": {
      "displayName": "Cullen D Molitor",
      "userId": "02217726571370409329"
     },
     "user_tz": 0
    },
    "id": "Hzvvsod9sY7Y",
    "outputId": "e2660848-281b-44ca-c4f0-25fc8cf860d6"
   },
   "outputs": [],
   "source": [
    "features = pd.read_feather(os.path.join(local_dir, \"SLE_features.feather\"))\n",
    "features.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AzRx3cjQd0nO"
   },
   "source": [
    "\n",
    "**Extracting Latitude and Longitude:**\n",
    "\n",
    "* The `image_id` contains latitude and longitude information encoded in its structure.\n",
    "* To use these for spatial analysis, we extract the latitude and longitude from the `image_id`.\n",
    "* The extracted values are stored as separate 'lat' and 'lon' columns in the DataFrame.\n",
    "* Features downloaded from the API come with latitude and longitude already\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "executionInfo": {
     "elapsed": 10350,
     "status": "ok",
     "timestamp": 1731577732429,
     "user": {
      "displayName": "Cullen D Molitor",
      "userId": "02217726571370409329"
     },
     "user_tz": 0
    },
    "id": "QmNHq6urj2Lv"
   },
   "outputs": [],
   "source": [
    "features[['lat_part', 'lon_part']] = features['image_id'].str.split('__', expand=True)\n",
    "features['lat'] = features['lat_part'].str.replace('lat_', '').str.replace('--', '.').astype(float)\n",
    "features['lon'] = features['lon_part'].str.replace('lon_', '').str.replace('--', '.').astype(float)\n",
    "features = features.drop(['lat_part', 'lon_part'], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "y1fuoz5-d--G"
   },
   "source": [
    "\n",
    "**Creating a GeoDataFrame:**\n",
    "\n",
    "* The pandas DataFrame is then transformed into a GeoDataFrame using the `geopandas` library. This step adds spatial capabilities to the data.\n",
    "* We create point geometries from the 'lat' and 'lon' columns, representing each feature's location on a map.\n",
    "* The coordinate reference system (CRS) is set to \"EPSG:4326\", ensuring proper interpretation of the spatial information.\n",
    "* Finally, a buffer of 0.005 is applied to each point geometry. This creates small circular polygons around each point, however we also include the argument `cap_style=3` which makes square corners. This effectively turns our point geometry into a polygon over the same physical space as the imagery the features were computed from.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 559
    },
    "executionInfo": {
     "elapsed": 862,
     "status": "ok",
     "timestamp": 1731577733288,
     "user": {
      "displayName": "Cullen D Molitor",
      "userId": "02217726571370409329"
     },
     "user_tz": 0
    },
    "id": "iK2_SX__HuZS",
    "outputId": "87716df2-3526-4941-ddf5-afcb68c1f0fd"
   },
   "outputs": [],
   "source": [
    "features = gpd.GeoDataFrame(\n",
    "    features,\n",
    "    geometry=gpd.points_from_xy(features.lon, features.lat),\n",
    "    crs=\"EPSG:4326\"\n",
    "  )\n",
    "features.geometry = features.geometry.buffer(0.005, cap_style=3)\n",
    "features.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ayG6mVGbeDAa"
   },
   "source": [
    "## Plot example features\n",
    "\n",
    "This completes the loading and preparation of the satellite features. The resulting GeoDataFrame, containing both feature values and geographic locations, is now ready to be joined with the ASM labels to link the two datasets based on spatial proximity. This integration will enable the machine learning model to associate satellite-derived characteristics with ASM presence or absence.\n",
    "\n",
    "**Plot**  \n",
    "- The plot here shows a single layer of random convolutional features\n",
    "- `feature_0` is chosen arbitrarily\n",
    "- We are unable to use the `.explore()` method due to constraints with system memory on the free tier of Google Colab   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 448
    },
    "executionInfo": {
     "elapsed": 22019,
     "status": "ok",
     "timestamp": 1731577755304,
     "user": {
      "displayName": "Cullen D Molitor",
      "userId": "02217726571370409329"
     },
     "user_tz": 0
    },
    "id": "fMr_SdYKHuWt",
    "outputId": "0e80dce4-1c83-40df-d55a-640f8eea7821"
   },
   "outputs": [],
   "source": [
    "features.plot(column = \"feature_0\", legend = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "A-jeA_phda5J"
   },
   "source": [
    "## Joining Labels to Features\n",
    "\n",
    "This section describes the process of joining the ASM label data with the satellite imagery features. This step is crucial for creating a dataset that links the location of potential ASM sites with their corresponding satellite-derived characteristics.\n",
    "\n",
    "**1. Spatial Join:**\n",
    "\n",
    "* We use the `geopandas.sjoin()` function to perform a spatial join between the labels GeoDataFrame (`labels_gdf`) and the features GeoDataFrame (`features`).\n",
    "* The `how=\"inner\"` argument ensures that only sites with both label and feature information are included in the resulting joined dataset.\n",
    "* The `predicate=\"intersects\"` argument specifies that the join should be based on spatial intersection. This means that a label will be joined to a feature if their geometries overlap.\n",
    "\n",
    "**2. Resulting Dataset:**\n",
    "\n",
    "* The spatial join creates a new GeoDataFrame called `joined`.\n",
    "* This GeoDataFrame contains all the columns from both the labels and features datasets, along with a new 'index_right' column indicating the index of the matching feature for each label.\n",
    "* This joined dataset is now ready for use in the subsequent model training and evaluation steps. The combined information allows the model to learn patterns between satellite imagery features and the presence of ASM activity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 429
    },
    "executionInfo": {
     "elapsed": 1947,
     "status": "ok",
     "timestamp": 1731577757247,
     "user": {
      "displayName": "Cullen D Molitor",
      "userId": "02217726571370409329"
     },
     "user_tz": 0
    },
    "id": "49eOjLLTHuT8",
    "outputId": "eb93a873-db9b-4127-9551-9c9081cbe3fa"
   },
   "outputs": [],
   "source": [
    "joined = gpd.sjoin(labels_gdf, features, how=\"inner\", predicate=\"intersects\")\n",
    "joined.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "51_f1-oKgm5l"
   },
   "source": [
    "## Model Training and Evaluation\n",
    "\n",
    "This section outlines the process of training a machine learning model to predict the likelihood of ASM presence based on the satellite imagery features, and evaluating its performance.\n",
    "\n",
    "**1. Data Preparation:**\n",
    "\n",
    "* The joined dataset is split into features (X) and the target variable (y).\n",
    "    * `X` contains the satellite imagery features, specifically the columns with names starting with 'feature_'.\n",
    "    * `y` contains the ASM label (1 for ASM presence, 0 for absence).\n",
    "* The data is further split into training and testing sets using `train_test_split` to evaluate the model's performance on unseen data.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "executionInfo": {
     "elapsed": 8,
     "status": "ok",
     "timestamp": 1731577757247,
     "user": {
      "displayName": "Cullen D Molitor",
      "userId": "02217726571370409329"
     },
     "user_tz": 0
    },
    "id": "xHYW9_MtqvbK"
   },
   "outputs": [],
   "source": [
    "feature_cols = [f\"feature_{i}\" for i in range(4000)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "executionInfo": {
     "elapsed": 7,
     "status": "ok",
     "timestamp": 1731577757247,
     "user": {
      "displayName": "Cullen D Molitor",
      "userId": "02217726571370409329"
     },
     "user_tz": 0
    },
    "id": "-hhKBLT22H6x"
   },
   "outputs": [],
   "source": [
    "X = joined[feature_cols].values\n",
    "y = joined[\"label\"].values\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=1991\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jvDddOStjJXl"
   },
   "source": [
    "**2. Model Selection and Training:**\n",
    "\n",
    "* A Ridge Regression model with Isotonic Calibration is used for prediction. This model is chosen for its ability to handle high-dimensional data and its robustness to outliers.\n",
    "    * **Ridge Regression** is a linear model that adds a penalty term to the loss function, preventing overfitting.\n",
    "    * **Isotonic Calibration** adjusts the model's predictions to improve their accuracy and reliability.\n",
    "* Hyperparameter tuning is performed using `GridSearchCV` to find the best value for the regularization parameter (`alpha`) of the Ridge Regression model. This helps to optimize the model's performance.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "executionInfo": {
     "elapsed": 7,
     "status": "ok",
     "timestamp": 1731577757247,
     "user": {
      "displayName": "Cullen D Molitor",
      "userId": "02217726571370409329"
     },
     "user_tz": 0
    },
    "id": "NpzS7Jqm2Pr6"
   },
   "outputs": [],
   "source": [
    "alphas = [0.01, 0.1, 1.0, 10.0]\n",
    "ridge = RidgeClassifier()\n",
    "param_grid = {'alpha': alphas}\n",
    "grid_search = GridSearchCV(\n",
    "    ridge,\n",
    "    param_grid,\n",
    "    cv=5,\n",
    "    scoring='roc_auc',\n",
    "    verbose=2,\n",
    "    n_jobs=-1\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 153
    },
    "collapsed": true,
    "executionInfo": {
     "elapsed": 49834,
     "status": "ok",
     "timestamp": 1731577807075,
     "user": {
      "displayName": "Cullen D Molitor",
      "userId": "02217726571370409329"
     },
     "user_tz": 0
    },
    "id": "pLziaFvw2TLW",
    "outputId": "c8ab1124-ee1e-4960-bff1-f9d7e63a4d60"
   },
   "outputs": [],
   "source": [
    "grid_search.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3Z_GbSPolMc2"
   },
   "source": [
    "**3. Model Evaluation:**\n",
    "\n",
    "* The trained model is evaluated using the testing set, which was not used during training.\n",
    "* The primary evaluation metric is the Receiver Operating Characteristic Area Under the Curve (ROC AUC). This metric measures the model's ability to distinguish between positive (ASM presence) and negative (ASM absence) cases.\n",
    "* The ROC curve is visualized to provide a graphical representation of the model's performance across different thresholds.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 5,
     "status": "ok",
     "timestamp": 1731577807076,
     "user": {
      "displayName": "Cullen D Molitor",
      "userId": "02217726571370409329"
     },
     "user_tz": 0
    },
    "id": "dRx0ASakxKBg",
    "outputId": "4925d8d1-1cfc-4b84-b57c-d1023e55609d"
   },
   "outputs": [],
   "source": [
    "# Get uncalibrated predictions (decision function)\n",
    "y_pred_uncal = grid_search.decision_function(X_test)\n",
    "\n",
    "# Fit isotonic calibration\n",
    "iso_reg = IsotonicRegression(out_of_bounds='clip')\n",
    "iso_reg.fit(y_pred_uncal, y_test)\n",
    "\n",
    "# Get calibrated predictions\n",
    "y_pred_cal = iso_reg.predict(y_pred_uncal)\n",
    "\n",
    "# Calculate AUC scores\n",
    "auc_uncal = roc_auc_score(y_test, y_pred_uncal)\n",
    "auc_cal = roc_auc_score(y_test, y_pred_cal)\n",
    "\n",
    "print(f\"Best alpha: {grid_search.best_params_['alpha']}\")\n",
    "print(f\"AUC before calibration: {auc_uncal:.3f}\")\n",
    "print(f\"AUC after calibration: {auc_cal:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 507
    },
    "executionInfo": {
     "elapsed": 604,
     "status": "ok",
     "timestamp": 1731577807677,
     "user": {
      "displayName": "Cullen D Molitor",
      "userId": "02217726571370409329"
     },
     "user_tz": 0
    },
    "id": "L4X6I-FJ2dnc",
    "outputId": "d7ae6105-12a0-423b-fe86-e34fa2a60318"
   },
   "outputs": [],
   "source": [
    "# Calculate ROC curves\n",
    "fpr_uncal, tpr_uncal, _ = roc_curve(y_test, y_pred_uncal)\n",
    "fpr_cal, tpr_cal, _ = roc_curve(y_test, y_pred_cal)\n",
    "\n",
    "# Create the plot\n",
    "plt.figure(figsize=(5, 5))\n",
    "\n",
    "# Plot both curves\n",
    "plt.plot(fpr_uncal, tpr_uncal, 'b-', label=f'Uncalibrated (AUC = {auc_uncal:.3f})')\n",
    "plt.plot(fpr_cal, tpr_cal, 'r-', label=f'Calibrated (AUC = {auc_cal:.3f})')\n",
    "\n",
    "# Plot the diagonal reference line\n",
    "plt.plot([0, 1], [0, 1], 'k--', label='Random')\n",
    "\n",
    "# Customize the plot\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('ROC Curves - Before and After Calibration')\n",
    "plt.legend(loc='lower right')\n",
    "plt.grid(True, alpha=0.3)\n",
    "\n",
    "# Set the plot limits\n",
    "plt.xlim([-0.01, 1.01])\n",
    "plt.ylim([-0.01, 1.01])\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WJPCsH9sleli"
   },
   "source": [
    "## Predicting ASM Probability Across Sierra Leone\n",
    "\n",
    "This section extends the analysis by applying the trained machine learning model to the entire feature set, generating predictions for the likelihood of ASM presence across Sierra Leone.\n",
    "\n",
    "**Prediction Process:**\n",
    "\n",
    "1. **Applying the Model:** The trained Ridge Regression model, along with the Isotonic Calibration, is used to predict the probability of ASM presence for each location in the feature dataset. This involves applying the model to the satellite imagery features associated with each location.\n",
    "\n",
    "2. **Storing Predictions:** The predicted probabilities are stored in a new column named 'predicted_probability' within the features GeoDataFrame. This column now represents the model's estimated likelihood of ASM activity at each location.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "executionInfo": {
     "elapsed": 1191,
     "status": "ok",
     "timestamp": 1731577808865,
     "user": {
      "displayName": "Cullen D Molitor",
      "userId": "02217726571370409329"
     },
     "user_tz": 0
    },
    "id": "3M95RIn4kl7S"
   },
   "outputs": [],
   "source": [
    "y_pred_full = grid_search.decision_function(features[feature_cols].values)\n",
    "y_pred_full_calibrated = iso_reg.predict(y_pred_full)\n",
    "\n",
    "features['predicted_probability'] = y_pred_full_calibrated\n",
    "# features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LyTqvPBnnckr"
   },
   "source": [
    "**Visualization:**\n",
    "\n",
    "- **Probability Map:** A map is generated using the `plot()` method to visualize the predicted probabilities spatially across Sierra Leone. Color gradients represent the predicted ASM probability, with areas of higher probability indicated by warmer colors (e.g., red, orange) and lower probability by cooler colors (e.g., blue, green).\n",
    "- This map provides a comprehensive view of potential ASM hotspots within the region based on the model's predictions.\n",
    "\n",
    "**Insights:**\n",
    "\n",
    "The generated probability map serves as a valuable tool for identifying and prioritizing areas for further investigation or potential interventions related to ASM. By visually highlighting areas of higher ASM likelihood, this analysis supports decision-making processes aimed at mitigating the negative impacts or harnessing the economic potential of ASM in Sierra Leone."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 821
    },
    "executionInfo": {
     "elapsed": 20446,
     "status": "ok",
     "timestamp": 1731577829307,
     "user": {
      "displayName": "Cullen D Molitor",
      "userId": "02217726571370409329"
     },
     "user_tz": 0
    },
    "id": "8IuuBP6foHql",
    "outputId": "6ea3b5b2-d0d1-4d6e-979a-d41afaa53b42"
   },
   "outputs": [],
   "source": [
    "# plt.figure(figsize=(10, 8))\n",
    "features.plot(\n",
    "    column=\"predicted_probability\",\n",
    "    cmap=\"viridis\",\n",
    "    legend=True,\n",
    "    legend_kwds={'label': \"Predicted ASM Probability\"},\n",
    "    figsize=(10, 10)\n",
    ")\n",
    "plt.title(\"Predicted ASM Probabilities Across Sierra Leone\")\n",
    "plt.xlabel(\"Longitude\")\n",
    "plt.ylabel(\"Latitude\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9KLtYhIZqbLH"
   },
   "source": [
    "## Conclusion\n",
    "\n",
    "This notebook demonstrated the use of machine learning and satellite imagery to identify potential artisanal and small-scale mining (ASM) sites in Sierra Leone. The process involved data acquisition, preprocessing, joining, model training and evaluation, and visualization and interpretation.\n",
    "\n",
    "The model showed promising results for the identification of ASM activity in Sierra Leone. The calibrated model is capable of capturing relevant signals from satellite imagery. The features are mostly likely highlighting things like bare earth, water, infrastructure, and changes in vegetation, which can indicate possible mining operations.\n",
    "\n",
    "This approach can be extended to analyze ASM in other regions, test alternative machine learning models, investigate specific mine types, and analyze additional satellite data sources or features.\n",
    "\n",
    "**Further Work**\n",
    "\n",
    "* Investigate the use of other machine learning models, such as Random Forest or Support Vector Machines.\n",
    "* Incorporate other data sources, such as geological data or socio-economic indicators.\n",
    "* Look at ASM hotspots on the prediction map and validate the signal in the imagery (ie. look for mines and make new labels).\n",
    "\n",
    "**Acknowledgements**\n",
    "\n",
    "We acknowledge the contributions of the Project on Resource Governance (PRG) from the University of Califronia Los Angeles, the Environmental Markets Lab (emLab) at the University of California Santa Barbara, and the Center for Effective Global Action (CEGA) at the University of California Berkeley in providing the data and support for this analysis.\n",
    "\n",
    "**Disclaimer**\n",
    "\n",
    "The results presented in this notebook are for informational and demonstration purposes only and should not be considered as definitive evidence of ASM activity. Further verification and ground-truthing are recommended for any decision-making related to ASM. The work behind this notebook is ongoing and is expected to be published within the next year."
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
