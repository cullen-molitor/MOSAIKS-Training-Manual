{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cp1-HnPiYUoh"
   },
   "source": [
    "# MOSAIKS Demonstration: Identifying Internet Access in Togo\n",
    "\n",
    "> **Note**: If you wish to save this notebook with any of your changes, please make sure to click on `File > Save a copy in Drive`. All changes will be lost if you close this tab without saving a copy in your Google Drive. All changes made before saving a copy in Drive will be saved in the notebook after you save a copy in Drive. Data is downloaded from the internet and stored in the temporary disk of the environment. This data will be deleted once the session is over.\n",
    "\n",
    "This notebook demonstrates the application of Multi-task Observation using Satellite Imagery & Kitchen Sinks (MOSAIKS), a machine learning approach utilizing satellite imagery, to identify areas with and without internet access in Togo. This information can be crucial for understanding the digital divide and informing policies to improve connectivity.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UGgU2UYC8mvt"
   },
   "source": [
    "## Methodology\n",
    "\n",
    "The process involves the following steps:\n",
    "\n",
    "1. **Data Acquisition:** Label data on internet access is provided by the Agence Togo Digital (ATD). Pre-processed satellite imagery features are derived using the MOSAIKS framework.\n",
    "1. **Data Preprocessing:** The label and feature data are preprocessed and cleaned. This leaves a single dataset with labels and features that is ready to use.\n",
    "1. **Model Training and Evaluation:** A machine learning model, specifically Ridge Regression with isotonic calibration, is trained on the joined dataset to predict the likelihood of internet access. The model is evaluated using metrics like the Receiver Operating Characteristic Area Under the Curve (ROC AUC).\n",
    "1. **Visualization and Interpretation:** The model results are visualized using maps and plots. Important features identified by the model are analyzed to understand the patterns associated with internet access.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "azwGr9_x8bfh"
   },
   "source": [
    "## Setup\n",
    "\n",
    "This notebook utilizes several key Python libraries:\n",
    "\n",
    "- **Data Handling and Analysis:** `pandas` and `numpy` provide fundamental data structures and functions for manipulating and analyzing data. `geopandas` extends these capabilities to work with geospatial data.\n",
    "- **Visualization:** `matplotlib.pyplot` and `seaborn` enable the creation of static and interactive visualizations, aiding in data exploration and result presentation.\n",
    "- **Machine Learning:** `sklearn` offers a comprehensive suite of tools for building and evaluating machine learning models, including algorithms like Ridge Regression and methods for data preprocessing.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "executionInfo": {
     "elapsed": 9323,
     "status": "ok",
     "timestamp": 1733431016832,
     "user": {
      "displayName": "Cullen D Molitor",
      "userId": "02217726571370409329"
     },
     "user_tz": 480
    },
    "id": "x6eczjTE2k3B"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import geopandas as gpd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# from google.colab import drive\n",
    "from sklearn.linear_model import RidgeCV\n",
    "from sklearn.calibration import IsotonicRegression\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "from scipy.linalg import LinAlgWarning\n",
    "\n",
    "warnings.filterwarnings(\n",
    "    \"ignore\", category=LinAlgWarning, module=\"sklearn.linear_model._ridge\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the directory name\n",
    "data_dir = \"LSMS-ISA-data\"\n",
    "\n",
    "# Check if the final directory exists\n",
    "if not os.path.exists(data_dir):\n",
    "    # Download only if the zip file doesn't exist\n",
    "    if not os.path.exists(\"Data.zip\"):\n",
    "        !wget https://zenodo.org/records/14040658/files/Data.zip\n",
    "\n",
    "    # Unzip the data\n",
    "    !unzip Data.zip\n",
    "\n",
    "    # Rename the folder\n",
    "    !mv Data {data_dir}\n",
    "\n",
    "    # Remove the zip file\n",
    "    !rm Data.zip\n",
    "\n",
    "# List the files (this will run regardless)\n",
    "!ls -lh {data_dir}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the directory and base URL\n",
    "geo_dir = \"geoBoundaries\"\n",
    "base_url = \"https://github.com/wmgeolab/geoBoundaries/raw/9469f09/releaseData/gbOpen\"\n",
    "\n",
    "# List of country codes\n",
    "countries = [\"ETH\", \"MWI\", \"MLI\", \"NER\", \"NGA\", \"TZA\", \"UGA\"]\n",
    "\n",
    "# Create directory if it doesn't exist\n",
    "if not os.path.exists(geo_dir):\n",
    "    !mkdir {geo_dir}\n",
    "\n",
    "# Download files for each country if they don't exist\n",
    "for country in countries:\n",
    "    filename = f\"geoBoundaries-{country}-ADM2.geojson\"\n",
    "    filepath = os.path.join(geo_dir, filename)\n",
    "\n",
    "    if not os.path.exists(filepath):\n",
    "        !wget {base_url}/{country}/ADM2/{filename} -P {geo_dir}\n",
    "\n",
    "# List the files (this will run regardless)\n",
    "!ls -lh {geo_dir}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !wget https://www.geoboundaries.org/data/geoBoundariesCGAZ-3_0_0/ADM2/simplifyRatio_100/geoBoundariesCGAZ_ADM2.topojson\n",
    "\n",
    "boundaries = gpd.read_file(\"geoBoundariesCGAZ_ADM2.topojson\")\n",
    "mask = boundaries[\"shapeID\"].str[:3].isin(countries)\n",
    "boundaries = boundaries[mask]\n",
    "boundaries = boundaries.rename(\n",
    "    columns={\n",
    "        \"shapeName\": \"ADM2\",\n",
    "        \"shapeGroup\": \"ADM0\",\n",
    "    }\n",
    ")\n",
    "boundaries = boundaries.drop(\n",
    "    columns=[\n",
    "        \"id\",\n",
    "        \"shapeISO\",\n",
    "        \"shapeType\",\n",
    "        \"ADM1_shapeID\",\n",
    "        \"ADM0_shapeID\",\n",
    "        \"ADMHIERARCHY\",\n",
    "    ]\n",
    ")\n",
    "boundaries = boundaries[[\"shapeID\", \"ADM0\", \"ADM2\", \"geometry\"]]\n",
    "boundaries.crs = \"EPSG:4326\"\n",
    "boundaries.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "executionInfo": {
     "elapsed": 27140,
     "status": "ok",
     "timestamp": 1733431067300,
     "user": {
      "displayName": "Cullen D Molitor",
      "userId": "02217726571370409329"
     },
     "user_tz": 480
    },
    "id": "5ITEdHZP3pdC",
    "outputId": "8ed5b405-3832-4d30-b230-785ec65ca1e2"
   },
   "outputs": [],
   "source": [
    "# feats = pd.read_csv(\n",
    "#     os.path.join(\n",
    "#         \"/\",\n",
    "#         \"home\",\n",
    "#         \"emlab\",\n",
    "#         \"data\",\n",
    "#         \"mosaiks-togo\",\n",
    "#         \"API_features\",\n",
    "#         \"ADM_2_regions_RCF_global_dense.csv\",\n",
    "#     )\n",
    "# )\n",
    "# mask = feats['shapeID'].str[:3].isin(countries)\n",
    "# feats = feats[mask]\n",
    "# feats = feats.drop(columns=[\"shapeID.1\"], errors=\"ignore\")\n",
    "# features = boundaries.set_index(\"shapeID\").join(feats.set_index(\"shapeID\"), how=\"left\")\n",
    "# features = features.reset_index()\n",
    "# new_cols = [col for col in features.columns if col != 'geometry'] + ['geometry']\n",
    "# features = features[new_cols]\n",
    "# features.crs = \"EPSG:4326\"\n",
    "# features.to_feather(\"adm2_api_features.feather\")\n",
    "# features.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feats2 = gpd.read_feather(\"adm2_api_features.feather\")\n",
    "feats2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_stata(os.path.join(data_dir, \"Plotcrop_dataset.dta\"))\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df = pd.read_stata(os.path.join(data_dir, \"Household_dataset.dta\"))\n",
    "df = pd.read_stata(os.path.join(data_dir, \"Plotcrop_dataset.dta\"))\n",
    "# Create a conditions dictionary mapping countries to their desired waves\n",
    "wave_conditions = {\n",
    "    \"Ethiopia\": 4,\n",
    "    \"Malawi\": 4,\n",
    "    \"Mali\": 2,\n",
    "    \"Niger\": 2,\n",
    "    \"Nigeria\": 3,\n",
    "    \"Tanzania\": 5,\n",
    "    \"Uganda\": 7,\n",
    "}\n",
    "\n",
    "# Create the filter using boolean indexing\n",
    "df = df[\n",
    "    df.apply(lambda x: x[\"wave\"] == wave_conditions.get(x[\"country\"], False), axis=1)\n",
    "]\n",
    "\n",
    "gdf = gpd.GeoDataFrame(\n",
    "    df, geometry=gpd.points_from_xy(df.lon_modified, df.lat_modified), crs=\"EPSG:4326\"\n",
    ")\n",
    "\n",
    "gdf = gdf.drop(\n",
    "    columns=[\n",
    "        \"admin_2\",\n",
    "        \"admin_3\",\n",
    "        \"hh_id_merge\",\n",
    "        \"hh_id_obs\",\n",
    "        \"season\",\n",
    "        \"ea_id_merge\",\n",
    "        \"ea_id_obs\",\n",
    "        \"strataid\",\n",
    "        \"geocoords_id\",\n",
    "    ]\n",
    ")\n",
    "\n",
    "gdf[\"admin_2_name\"] = gdf[\"admin_2_name\"].replace(\"\", np.nan)\n",
    "\n",
    "mask_coords = gdf[\"geometry\"].is_empty == False\n",
    "gdf_with_coords = gdf[mask_coords].copy()\n",
    "\n",
    "joined_data = gpd.sjoin(\n",
    "    gdf_with_coords, boundaries[[\"ADM2\", \"geometry\"]], how=\"left\", predicate=\"within\"\n",
    ")\n",
    "\n",
    "gdf[\"admin_2_joined\"] = None\n",
    "\n",
    "gdf.loc[joined_data.index, \"admin_2_joined\"] = joined_data[\"ADM2\"]\n",
    "\n",
    "gdf[\"ADM2\"] = gdf[\"admin_2_name\"].fillna(gdf[\"admin_2_joined\"])\n",
    "\n",
    "gdf = gdf.drop(\n",
    "    columns=[\n",
    "        \"wave\",\n",
    "        \"admin_2_joined\",\n",
    "        \"geometry\",\n",
    "        \"lat_modified\",\n",
    "        \"lon_modified\",\n",
    "        \"admin_1\",\n",
    "        \"admin_1_name\",\n",
    "        \"admin_2_name\",\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Create dictionary of country names to ISO3 codes\n",
    "country_to_iso3 = {\n",
    "    \"Ethiopia\": \"ETH\",\n",
    "    \"Malawi\": \"MWI\",\n",
    "    \"Mali\": \"MLI\",\n",
    "    \"Niger\": \"NER\",\n",
    "    \"Nigeria\": \"NGA\",\n",
    "    \"Tanzania\": \"TZA\",\n",
    "    \"Uganda\": \"UGA\",\n",
    "}\n",
    "\n",
    "# Create new ADM0 column using map\n",
    "gdf[\"ADM0\"] = gdf[\"country\"].map(country_to_iso3)\n",
    "\n",
    "new_cols = [\"country\", \"ADM2\"] + [\n",
    "    col for col in gdf.columns if col not in [\"country\", \"ADM2\"]\n",
    "]\n",
    "gdf = gdf[new_cols]\n",
    "\n",
    "gdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gdf.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert Yes/No to 1/0\n",
    "binary_cols = [\"urban\", \"hh_electricity_access\"]\n",
    "for col in binary_cols:\n",
    "    gdf[col] = (gdf[col] == \"Yes\").astype(int)\n",
    "\n",
    "# Identify numeric columns to aggregate\n",
    "numeric_cols = gdf.select_dtypes(include=[\"float64\", \"int64\"]).columns\n",
    "numeric_cols = [\n",
    "    col for col in numeric_cols if col != \"pw\" and col != \"ADM0\"\n",
    "]  # exclude weight column\n",
    "\n",
    "# Create weighted means by ADM2\n",
    "summary = []\n",
    "for adm2 in gdf[\"ADM2\"].dropna().unique():\n",
    "    subset = gdf[gdf[\"ADM2\"] == adm2]\n",
    "\n",
    "    # Skip if subset is empty\n",
    "    if len(subset) == 0:\n",
    "        continue\n",
    "\n",
    "    country = subset[\"country\"].iloc[0]\n",
    "    # adm0 = subset[\"ADM0\"].iloc[0]\n",
    "\n",
    "    # Calculate weighted means for each numeric column\n",
    "    weighted_means = {\n",
    "        \"country\": country,\n",
    "        # \"ADM0\": adm0,\n",
    "        \"ADM2\": adm2,\n",
    "        \"n_households\": len(subset),\n",
    "    }\n",
    "\n",
    "    for col in numeric_cols:\n",
    "        # Remove NaN values before calculating weighted average\n",
    "        mask = ~subset[col].isna()\n",
    "        if mask.any():  # if there are any non-NaN values\n",
    "            weighted_means[col] = np.average(\n",
    "                subset[col][mask], weights=subset[\"pw\"][mask]\n",
    "            )\n",
    "        else:\n",
    "            weighted_means[col] = np.nan\n",
    "\n",
    "    summary.append(weighted_means)\n",
    "\n",
    "# Convert to DataFrame\n",
    "summary_df = pd.DataFrame(summary)\n",
    "\n",
    "# Reorder columns to match original\n",
    "new_cols = [\"country\", \"ADM2\", \"n_households\"] + [\n",
    "    col for col in numeric_cols if col in summary_df.columns\n",
    "]\n",
    "summary_df = summary_df[new_cols]\n",
    "summary_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [],
   "source": [
    "summary_df[\"ADM2\"] = summary_df[\"ADM2\"].str.title()\n",
    "feats2[\"ADM2\"] = feats2[\"ADM2\"].str.title()\n",
    "\n",
    "summary_df[\"ADM2\"] = summary_df[\"ADM2\"].str.replace(\" Rural\", \"\").str.strip()\n",
    "feats2[\"ADM2\"] = feats2[\"ADM2\"].str.replace(\" Rural\", \"\").str.strip()\n",
    "\n",
    "# Create a dictionary of corrections\n",
    "corrections = {\n",
    "    \"Birni N'Konni\": \"Bkonni\",\n",
    "    \"Butiama\": \"Butiam\",\n",
    "    \"Guidan-Roumdji\": \"Guidan Roumji\",\n",
    "    \"Illéla\": \"Illela\",\n",
    "    \"Matamèye\": \"Matameye\",\n",
    "    \"Tchin-Tabaraden\": \"Tchintabaraden\",\n",
    "    \"Tillaberi\": \"Tillabéri\",\n",
    "    \"Maïné-Soroa\": \"Maïné Soroa\",\n",
    "    \"Abia\": \"Abi\",\n",
    "    \"Anambra East\": \"Anambra\",\n",
    "    \"Babati Urban\": \"Babati\",\n",
    "    \"Kigoma Ujiji Urban\": \"Kigoma Urban\",\n",
    "    \"Niamey1\": \"Niamey\",\n",
    "    \"Babati Town\": \"Babati Urban\",\n",
    "    \"Kahama Town\": \"Kahama Township Authority\",\n",
    "    \"Korogwe Urban\": \"Korogwe Township Authority\",\n",
    "    \"Mafinga Town\": \"Mafinga Township Authority\",\n",
    "    \"Masasi Urban\": \"Masasi Township Authority\",\n",
    "    \"Mtwara Mikindani\": \"Mtwara Urban\",\n",
    "    \"Nzega Town\": \"Nzega Township Authority\",\n",
    "    \"Kasulu Town\": \"Kasulu Township Authority\",\n",
    "    \"Chakechake\": \"Chake Chake\",\n",
    "    \"Fct Abuja\": \"Abuja Municipal\",\n",
    "    \"Handeni Mji\": \"Handeni Urban\",\n",
    "    \"Makambako Town\": \"Makambako Township Authority\",\n",
    "    \"Chakechake\": \"Chake Chake\",  # In case of variations without capitalization\n",
    "    \"Masasi  Township Authority\": \"Masasi Township Authority\",\n",
    "}\n",
    "\n",
    "# Apply corrections to both dataframes\n",
    "for old_name, new_name in corrections.items():\n",
    "    summary_df[\"ADM2\"] = summary_df[\"ADM2\"].replace(old_name, new_name)\n",
    "    feats2[\"ADM2\"] = feats2[\"ADM2\"].replace(old_name, new_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get sets of unique values from each dataset\n",
    "set1 = set(summary_df[\"ADM2\"].unique())\n",
    "set2 = set(feats2[\"ADM2\"].unique())\n",
    "\n",
    "# Find values that appear in one dataset but not the other\n",
    "only_in_summary = set1 - set2\n",
    "only_in_feats = set2 - set1\n",
    "\n",
    "print(\"Values only in summary_df:\", sorted(only_in_summary))\n",
    "print(\"Values only in feats2:\", sorted(only_in_feats))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted(only_in_summary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = summary_df.merge(feats2, on=[\"ADM2\"], how=\"left\")\n",
    "data = data.dropna()\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import RidgeCV\n",
    "from sklearn.calibration import IsotonicRegression\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {
    "executionInfo": {
     "elapsed": 3,
     "status": "ok",
     "timestamp": 1733431071451,
     "user": {
      "displayName": "Cullen D Molitor",
      "userId": "02217726571370409329"
     },
     "user_tz": 480
    },
    "id": "xHYW9_MtqvbK"
   },
   "outputs": [],
   "source": [
    "feature_cols = [f\"X_{i}\" for i in range(4000)]\n",
    "# feature_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.columns[3:25]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {
    "executionInfo": {
     "elapsed": 5460,
     "status": "ok",
     "timestamp": 1733431076908,
     "user": {
      "displayName": "Cullen D Molitor",
      "userId": "02217726571370409329"
     },
     "user_tz": 480
    },
    "id": "-hhKBLT22H6x"
   },
   "outputs": [],
   "source": [
    "X = data[feature_cols].values\n",
    "y = data[\"nb_plots\"].values\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alphas = np.logspace(-8, 8, base=10, num=17)\n",
    "ridge = RidgeCV(alphas=alphas, scoring=\"r2\", cv=5)\n",
    "\n",
    "ridge.fit(X_train, y_train)\n",
    "\n",
    "y_pred = np.maximum(ridge.predict(X_test), 0)\n",
    "\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "print(f\"Best alpha: {ridge.alpha_}\")\n",
    "print(f\"Validation R2 performance {ridge.best_score_:0.2f}\")\n",
    "print(f\"Test R2 performance {r2:.4f}\")"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "mosaiks",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
