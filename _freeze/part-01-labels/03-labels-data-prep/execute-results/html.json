{
  "hash": "e5a635a5baa9d8f23e2c352c5a7fa6eb",
  "result": {
    "engine": "knitr",
    "markdown": "# Preparing labels {#sec-labels-data-prep}\n\n\n\n\n\n\n:::: status\n::: callout-warning \nThis chapter is in early draft form and may be incomplete.\n:::\n::::\n\n\n\n\n## Overview\n\nIn this chapter, we'll cover the process of preparing labels for use with MOSAIKS features. Labels are the observed values that we want to predict using our model. These could be crop yields, disease incidence, or any other variable of interest. Label data can come in many forms, including point observations, polygon aggregates, or gridded rasters, but the key is that they must have a sptaial component. We take advantage of this spatial information to join the labels with the MOSAIKS features, which are also spatially explicit.\n\nWhile MOSAIKS can involve many optional steps, its effective utilization necessitates two core components: \n\n1. Ground observations (labels)\n1. Satellite features\n\nEnsuring the spatial resolution is shared across both datasets and that they contain geographical data suitable for merging is crucial.\n\n## Ground observations\n\n### Resolution  \n\n::: {.callout-note}\n\nThe MOSAIKS API is designed to predict outcomes at scales of 1 km² or larger. Customizable solutions are possible for higher resolution problems. \n:::\n\nThe preparation of label data for MOSAIKS hinges on multiple factors, particularly spatial information such as location, extent, and resolution. If the observations in a dataset have a higher resolution than 1 km², some form of selection or aggregation is required. Label data can come in any native spatial form: raster, point, polygon, or vector. As long as there is spatial information associated with each label data observation, these data can be joined to MOSAIKS imagery features for downstream prediction.\n\n![Examples of label data formats that can be easily integrated into the MOSAIKS pipeline. Label data of any spatial format that can be aggregated to at least the scale of 1km² (or larger) can be used directly in combination with MOSAIKS imagery features for downstream prediction tasks. Examples shown here are from Rolf et al. (2021) and include: forest cover, elevation, population, and nighttime lights datasets (all raster format); income data (polygon format); road length (vector format); and housing price data (point format).](../images/rolf_et_al_2021-Fig_S4.png){#fig-label-agg}\n\n### Sample size  \n\nAs with many machine learning algorithms, a large sample size often results in higher performance than low. MOSAIKS has been used and shown to be effective with a wide range of sample sizes (*N*). The sample size for model training is determined by the spatial and temporal resolution of your label data. For example, when predicting maize yields in the US using ground data from one year of farmer-level surveys in the US, *N*=3,143 if farmers are geolocated based on their county (even if far more than 3,143 farmers were interviewed, as this is the number of counties in the US). Additional time periods increase sample size for training, but also require more up-front costs, as more imagery need to be “featurized”.\n\nThe original MOSAIKS publication (Rolf et al., 2021) tested performance for forest cover, income, housing price, population density, nighttime luminosity, and elevation using sample sizes ranging from 60,000 to 100,000, but showed that performance fell only modestly when *N* shrank to just a few hundred observations. Consistent with this finding, in recent experiments with crop yield, we see high with only around 400 observations (R² = 0.80). It is important to note that the original crop yield dataset included interview data from thousands of farmers across the study country, and this messy data was cleaned and aggregated to the district level prior to modeling. In this case, a clean dataset with a low number of observations was preferred to a large but noisy dataset. Despite the low sample size of the aggregate data, performance was still comparable to more complex CNN models trained specifically on crop yield. \n\n::: {.callout-note}\nAs a rule of thumb, we recommend a sample size of at least 300 observations for training a MOSAIKS model, though every application is unique and may require more or fewer observations.\n:::\n\n### Data types\n\nMOSAIKS accommodates both continuous (e.g., fraction of area forested) and discrete (e.g., presence/absence of water) labels, with data type influencing model development and testing. Performance metric selection is also determined by data type - for continuous variables, we typically use the coefficient of determination (R²), while for discrete variables, the area under the curve value from the receiver operator characteristic curve (ROC AUC score) is used.\n\n### Checklist\n\nFor optimal use with MOSAIKS, label data should be:\n\n- [ ] **Consistently geolocated** as point, polygon, vector, or raster data\n- [ ] **Aggregatable to ≥1km²** resolution\n- [ ] **Observable** in daytime satellite imagery (directly or indirectly)\n- [ ] **Recent or slow-changing** if using current API features\n- [ ] **Sample size N≥300** (larger samples generally perform better)\n\n## Joining data\n\nBefore model training, label data must be joined to imagery features. The joined data should be tabular with each row containing:\n\n1. **Label** - the observed value  \n1. **Geographic location** - such as a MOSAIKS grid cell or larger geographic area  \n1. **Time (optional)** - useful for time series data (year, mont, or day)  \n1. ***K* feature columns** - column for every random satellite feature (typically *k* = 4,000)  \n\nFor example, a dataset with crop yeild data could look like:\n\n| Observation | District  | Year | Crop Yield | \n|-------------|-----------|------|------------|\n| 1           | Chibombo  | 2019 | 1.520      | \n| 2           | Kabwe     | 2019 | 1.878      | \n| ...         | ...       | ...  | ...        | \n| *N*         | Kitwe     | 2019 | 2.383      | \n\nAnd a dataset with district level aggregate features could look like:\n\n| Observation | District  | Year | Feature 1 | Feature 2 | ... | Feature *K* |\n|-------------|-----------|------|-----------|-----------|-----|-------------|\n| 1           | Chibombo  | 2019 | 4.2       | 11.6      | ... | 12.7        |\n| 2           | Kabwe     | 2019 | 2.9       | 5.3       | ... | 11.2        |\n| ...         | ...       | ...  | ...       | ...       | ... | ...         |\n| *N*         | Kitwe     | 2019 | 10.6      | 1.1       | ... | 2.2         |\n\nFinally, the joined dataset would look like:\n\n| Observation | District  | Year | Crop Yield | Feature 1 | Feature 2 | ... | Feature *K* |\n|-------------|-----------|------|------------|-----------|-----------|-----|-------------|\n| 1           | Chibombo  | 2019 | 1.520      | 4.2       | 11.6      | ... | 12.7        |\n| 2           | Kabwe     | 2019 | 1.878      | 2.9       | 5.3       | ... | 11.2        |\n| ...         | ...       | ...  | ...        | ...       | ...       | ... | ...         |\n| *N*         | Kitwe     | 2019 | 2.383      | 10.6      | 1.1       | ... | 2.2         |\n\nIn the above example, our geographic location is the district and our label is the crop yield (mt/ha). We then have *K* columns containing the features and *N* observations. \n\nIn this example, our features started at 1 km² resolution and were aggregated to the district level to match the crop yield data. To join this data, we first found all of the feature locations that fall within the district boundaries using a spatial join. Then we averaged the features within each district. This allowed us to have a single feature vector for each district. The resulting tabular data is ready for modeling.\n\n## Data cleaning considerations\n\nBefore joining label data with MOSAIKS features, several key preparation steps should be considered:\n\n### Geographic information\n\n- **Coordinate systems**: Ensure coordinates are in a projection consistent with the features (API uses decimal degrees - WGS84) (@fig-map-projections)\n- **Spatial units**: Convert all geographic boundaries to same format (e.g., administrative regions)\n- **Resolution matching**: Aggregate or disaggregate data to match MOSAIKS grid\n- **Duplicate checking**: Remove duplicate locations within same time period\n- **Missing coordinates**: Handle missing or invalid geographic information\n\n![[Nine small-scale map projections](https://www.researchgate.net/publication/273517879_User_preferences_for_world_map_projections)](https://www.researchgate.net/profile/Bojan-Savric/publication/273517879/figure/fig1/AS:347863067447297@1459948426262/The-nine-small-scale-map-projections-used-in-the-paired-comparison-test-arranged-by.png){#fig-map-projections}\n\n### Label quality\n\n- **Outliers**: Identify and handle extreme values\n- **Missing values**: Decide on approach for handling NA/NULL values\n- **Units**: Convert all measurements to consistent units\n- **Data types**: Ensure numeric fields are properly formatted\n- **Range checks**: Verify values fall within expected bounds\n\n### Temporal alignment \n\n- **Time periods**: Match observation dates with feature timestamps\n- **Seasonality**: Account for seasonal patterns in data collection\n- **Aggregation**: Consider temporal aggregation needs (e.g., annual averages)\n- **Gaps**: Handle missing time periods appropriately\n\n## Data formats\n\n::: {.callout-tip}\nWhen working with large datasets, consider using efficient data formats like parquet, feather, GeoTIFF, or Zarr to reduce memory usage and speed up processing.\n:::\n\nMOSAIKS can work with several common spatial data formats:\n\n### Point data\n\nCommon for survey locations or specific measurement sites:\n\n```python\n# Example point data format\npoint_data = pd.DataFrame({\n    'longitude': [-15.416667, -15.308333, -15.200000],\n    'latitude': [28.316667, 28.441667, 28.550000],\n    'year': [2019, 2019, 2019],\n    'yield': [1.52, 1.88, 2.38]\n})\n```\n\nPoint data is typically joined to the nearest grid cell centroid or aggregated to larger polygons like administrative units (districts, provinces, etc.).\n\n### Polygon data\n\nUsed for administrative boundaries or management units:\n\n```python\n# Example polygon data format (GeoJSON-like)\npolygon_data = {\n    'type': 'Feature',\n    'properties': {\n        'district': 'Chibombo',\n        'year': 2019,\n        'yield': 1.52\n    },\n    'geometry': {\n        'type': 'Polygon',\n        'coordinates': [[[...coordinates...]]]\n    }\n}\n```\n\n### Raster data\n\nCommon for gridded observations or model outputs:\n\n```python\n# Example raster metadata\nraster_meta = {\n    'driver': 'GTiff',\n    'dtype': 'float32',\n    'nodata': -9999,\n    'width': 1000,\n    'height': 1000,\n    'crs': 'EPSG:4326',\n    'transform': [0.01, 0, -15.5, 0, -0.01, 28.6]\n}\n```\n\n## Joining procedures\n\nThe process of joining labels to features depends on your data format:\n\n### Point to grid matching\n\nFor point observations that don't align perfectly with the MOSAIKS grid:\n\n```python\ndef match_points_to_grid(points_df, grid_size=0.01):\n    \"\"\"\n    Match point observations to MOSAIKS grid cells\n    \n    Parameters:\n    -----------\n    points_df : pandas DataFrame\n        Contains 'longitude' and 'latitude' columns\n    grid_size : float\n        Size of grid cells in degrees (default 0.01 for ~1km)\n        \n    Returns:\n    --------\n    DataFrame with points matched to grid cell centroids\n    \"\"\"\n    # Round coordinates to nearest grid cell center\n    points_df['grid_lon'] = (np.floor(points_df['longitude'] / grid_size) * \n                            grid_size + grid_size/2)\n    points_df['grid_lat'] = (np.floor(points_df['latitude'] / grid_size) * \n                            grid_size + grid_size/2)\n    return points_df\n```\n\n### Polygon aggregation\n\nFor labels defined over administrative regions or other polygons:\n\n```python\ndef aggregate_features_to_polygons(features_df, polygons_gdf):\n    \"\"\"\n    Aggregate grid cell features to polygon level\n    \n    Parameters:\n    -----------\n    features_df : pandas DataFrame\n        Grid cell features with 'longitude' and 'latitude'\n    polygons_gdf : geopandas GeoDataFrame\n        Polygon boundaries\n        \n    Returns:\n    --------\n    DataFrame with features averaged within each polygon\n    \"\"\"\n    # Convert features to GeoDataFrame\n    features_gdf = gpd.GeoDataFrame(\n        features_df, \n        geometry=gpd.points_from_xy(features_df.longitude, \n                                  features_df.latitude)\n    )\n    \n    # Spatial join\n    joined = gpd.sjoin(features_gdf, polygons_gdf)\n    \n    # Average features within polygons\n    return joined.groupby('index_right').mean()\n```\n\n### Raster alignment\n\nFor gridded data that needs to be aligned with MOSAIKS grid:\n\n```python\ndef align_raster_to_mosaiks(raster_array, raster_transform, \n                           target_transform):\n    \"\"\"\n    Align raster data to MOSAIKS grid\n    \n    Parameters:\n    -----------\n    raster_array : numpy array\n        Source raster data\n    raster_transform : affine.Affine\n        Source raster geotransform\n    target_transform : affine.Affine\n        MOSAIKS grid geotransform\n        \n    Returns:\n    --------\n    Numpy array aligned to MOSAIKS grid\n    \"\"\"\n    # Implement resampling logic here\n    # Could use rasterio.warp.reproject or similar\n    pass\n```\n\n## Final data format\n\nAfter joining, your data should be in a tabular format ready for modeling:\n\n```python\n# Example final format\nmodel_data = pd.DataFrame({\n    'id': range(n_obs),\n    'longitude': [...],  # Grid cell or polygon centroid\n    'latitude': [...],   # Grid cell or polygon centroid\n    'year': [...],       # Time period if relevant\n    'label': [...],      # Target variable\n    'feature_0': [...],  # First MOSAIKS feature\n    'feature_1': [...],  # Second MOSAIKS feature\n    # ... additional features ...\n    'feature_3999': [...] # Last MOSAIKS feature\n})\n```\n\n**Note:** Add example notebook focusing on joining data with different data type examples\n\n::: {.callout-note}\n# Looking forward\n\nIn the next chapter we'll look at working specifically with survey data, which presents unique challenges for spatial joining and aggregation.\n:::\n",
    "supporting": [],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}