
# Try MOSAIKS {#sec-intro-demo}

```{r}
#| echo: false
#| results: "asis"

source("../_common.R")
status("testing")
```

## Overview

This demo replicates key results from the original MOSAIKS publication (Rolf et al. 2021). While MOSAIKS has great potential to improve access to satellite-based prediction in data-sparse environments, the original paper focused on demonstrating performance in the United States where high-quality training data was readily available.

The US served as an ideal testing ground for several reasons:

- Extensive ground truth data available across multiple variables
- Reliable spatial referencing of data
- Diverse landscapes and built environments
- Ability to benchmark against existing methods
- Systematic validation of predictions

This validation in a data-rich environment was crucial for establishing MOSAIKS as a reliable tool before deploying it in contexts where ground truth data is scarce or unreliable. 

## Demonstration code

### Workflow

Below is a link to a Jupyter notebook intended to demonstrate practical use of MOSAIKS with real data. In fact, this notebook uses the original input data and features from Rolf et al. 2021. The code demonstrates:

1. Loading pre-computed MOSAIKS features and labels
2. Merging the features and labels
3. Training a ridge regression model
4. Evaluating predictions
5. Visualizing results

### Label data

The demo showcases MOSAIKS predicting several variables, and with a subset of the data used in, the original paper. The variables include:

::: {.panel-tabset}

## Forest Cover

![Forest cover input data (left) from Global Land Analysis & Discover (GLAD) [Global 2010 Tree Cover (30 m)](https://glad.umd.edu/dataset/global-2010-tree-cover-30-m)](../images/f2_tree_cover.jpg){#fig-forest-cover}

## Elevation

![Elevation input data (left) provided by Mapzen, and accessed via the Amazon Web Services (AWS) Terrain Tile service. Download code can be found [here](https://www.github.com/jhollist/elevatr).](../images/f2_elevation.jpg){#fig-elevation}

## Population Density

![Population density input data (left) from the Gridded Population of the World (GPW) dataset. These data can be accessed [here](http://sedac.ciesin.columbia.edu/data/collection/gpw-v4).](../images/f2_population.jpg){#fig-population}

## Nighttime Lights

![Nighttime lights luminosity input data (left) generated from nighttime satellite imagery, which is provided by the Earth Observations Group at the National Oceanic and Atmospheric Administration (NOAA) and the National Geophysical Data Center (NGDC). These data can be accessed [here](https://eogdata.mines.edu/products/vnl/).](../images/f2_night_lights.jpg){#fig-night-lights}

## Income

![Income input data (left) from the American Community Survey (ACS) 5-year estimates of median annual household income in 2015. These data are accessible using the [acs package](https://cran.r-project.org/web/packages/acs/acs.pdf) in R (48), table number B19013](../images/f2_income.jpg){#fig-income}

## Road Length

![Road length input data (left) from the United States Geological Survey (USGS) National Transportation Dataset, which is based on TIGER/Line data provided by US Census Bureau in 2016. These data can be accessed [here](https://prd-tnm.s3.amazonaws.com/index.html?prefix=StagedProducts/Tran/Shape/).](../images/f2_road_length.jpg){#fig-road-length}

:::

A user simply needs to select which variable they would like to predict, and no other changes need to be made to the code. All data has been preprocessed and the code will download the necessary files from Zenodo.

### Constraints

To stay within the Colab free tier limits of memory usage, we subset the data. We take a 50% random sample of both features (*K*=4,000 instead of 8,192) and observations (*N*=50,000 instead of 100,000) compared to the original paper. Despite using this reduced dataset, the demo still achieves strong predictive performance, highlighting MOSAIKS's efficiency.

## Run the code!

::: {.callout-note}
# Click the badge to run the demonstration! 

&darr;&darr;&darr;&darr;&darr;&darr;&darr;&darr;&darr;&darr;&darr;&darr;&darr;&darr;&darr;&darr;   
[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/cullen-molitor/MOSAIKS-Training-Manual/blob/main/notebooks/demo/01-Rolf_et_al_2021_demo.ipynb)  
<!-- &uarr;&uarr;&uarr;&uarr;&uarr;&uarr;&uarr;&uarr;&uarr;&uarr;&uarr;&uarr;&uarr;&uarr;&uarr;&uarr;     -->
Remember to click `File` -> `Save a copy in Drive` to save any changes you make.  
---
Or to view a static version of the code on GitHub, click the badge below.  
[![](https://img.shields.io/badge/View%20on%20GitHub-181717?logo=github&logoColor=white&labelColor=grey&color=black&link=--)](https://github.com/cullen-molitor/MOSAIKS-Training-Manual/blob/main/notebooks/demo/01-Rolf_et_al_2021_demo.ipynb)
:::

For instructions and tips on using Google Colab, please refer to @sec-intro-compute. 

## Don't want to run code?

Consider watching this demonstration instead!

::: {#fig-demo}

{{< video https://www.youtube.com/embed/ux2c-ot3Ce0?si=Oalkj-4MsJN5hNCh >}}

An overview of MOSAIKS and a live demonstration of generating novel predictions using the system. Video recorded by CIGAR Generalized Planetary Remote Sensing - 2020 Convention session. Presented by Esther Rolf and Tamma Carleton.
:::

## What's next? 

After establishing MOSAIKS's capabilities in the US context, the MOSAIKS development team have successfully demonstrated the system in many additional settings. This includes on the global scale, or in settings with few or low quality data. In the coming chapters, we will explore some of these applications, showing how MOSAIKS can help address data gaps in regions where traditional data collection is challenging or costly.

::: {.callout-note}
# Looking forward

In the next section we will take a closer look at the label data that can be used with MOSAIKS. 
:::
